---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
spec:
  chartRef:
    kind: OCIRepository
    name: litellm
  interval: 1h
  timeout: 15m
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    cleanupOnFail: true
    remediation:
      retries: 3
      remediateLastFailure: true
  # Skip Helm tests - chart has bug in test-env-vars.yaml expecting DD_* vars
  test:
    enable: false
  values:
    # ============================================================
    # Image Configuration
    # IMPORTANT: Use litellm-non_root image which has proper Prisma
    # binary compatibility. The litellm-database and standard images
    # use Chainguard/wolfi base which causes Prisma query engine
    # timeouts due to missing OpenSSL 3.6.0 (falls back to Debian
    # binaries that don't work in wolfi).
    # See: https://github.com/BerriAI/litellm/issues/17093
    # See: https://github.com/BerriAI/litellm/issues/11864
    # ============================================================
    image:
      # litellm-non_root image with working Prisma binaries
      repository: litellm/litellm-non_root
      tag: v1.80.5-stable.1
      pullPolicy: IfNotPresent

    # ============================================================
    # Replica Configuration (HPA handles scaling)
    # ============================================================
    replicaCount: 2

    # ============================================================
    # Deployment Strategy
    # Conservative RollingUpdate prevents cascading failures during
    # slow startups with Prisma engine initialization
    # ============================================================
    strategy:
      type: RollingUpdate
      rollingUpdate:
        # Only surge by 1 pod at a time to limit failed pod accumulation
        maxSurge: 1
        # Keep at least 50% available during updates
        maxUnavailable: 0

    # ============================================================
    # Resource Configuration
    # ============================================================
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "2000m"
        memory: "2Gi"

    # ============================================================
    # Service Configuration
    # ============================================================
    service:
      type: ClusterIP
      port: 4000

    # ============================================================
    # Database Configuration (use external CloudNativePG)
    # ============================================================
    db:
      useExisting: true
      deployStandalone: false
      endpoint: litellm-db-rw
      database: litellm
      secret:
        name: litellm-db-secret
        usernameKey: username
        passwordKey: password

    # ============================================================
    # Migration Job Configuration
    # ============================================================
    migrationJob:
      enabled: false  # Disable - has permission issues with non-root

    # ============================================================
    # Environment Variables (simple key-value map)
    # ============================================================
    envVars:
      STORE_MODEL_IN_DB: "true"
      REDIS_HOST: "litellm-dragonfly"
      REDIS_PORT: "6379"
      REDIS_NAMESPACE: "litellm"
      LITELLM_MIGRATION_DIR: "/tmp"
      LITELLM_CALLBACKS: "prometheus"
      AZURE_API_BASE: "https://aaronsai.openai.azure.com/"
      AZURE_API_VERSION: "2025-01-01-preview"
      AZURE_API_BASE_EAST2: "https://ets-east-us2.openai.azure.com/"
      AZURE_API_VERSION_EAST2: "2025-04-01-preview"
      AZURE_ANTHROPIC_API_BASE: "https://ets-east-us2.services.ai.azure.com/anthropic"
      AZURE_COHERE_RERANK_API_BASE: "https://aan-cohere-rerank-v3-5.eastus.models.ai.azure.com/v2/rerank"
      AZURE_COHERE_EMBED_API_BASE: "https://aaronsai.services.ai.azure.com/models"
      LANGFUSE_HOST: "https://aiops.matherly.net"

    # ============================================================
    # Extra Environment Variables (K8s env spec with secretKeyRef)
    # ============================================================
    extraEnvVars:
      - name: LITELLM_MASTER_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_MASTER_KEY
      - name: LITELLM_SALT_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_SALT_KEY

      # UI Authentication (default: admin / MASTER_KEY)
      - name: UI_USERNAME
        value: "admin"
      - name: UI_PASSWORD
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_MASTER_KEY

      # Redis/Dragonfly Cache Password
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: REDIS_PASSWORD

      # Azure OpenAI US East
      - name: AZURE_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY

      # Azure OpenAI US East2
      - name: AZURE_API_KEY_EAST2
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY_EAST2

      # Azure Cohere Rerank API
      - name: AZURE_COHERE_RERANK_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_COHERE_RERANK_API_KEY

      # Azure Cohere Embed API
      - name: AZURE_COHERE_EMBED_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_COHERE_EMBED_API_KEY

      # Azure Anthropic API (Claude models via Azure AI)
      - name: AZURE_ANTHROPIC_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_ANTHROPIC_API_KEY

      # Langfuse Observability
      - name: LANGFUSE_PUBLIC_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_PUBLIC_KEY
      - name: LANGFUSE_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_SECRET_KEY

    # ============================================================
    # Config File (mounted from ConfigMap)
    # ============================================================
    proxyConfigMap:
      create: false
      name: litellm-config
      key: config.yaml

    # ============================================================
    # Probes Configuration
    # Prisma engine initialization can take 30-60s on cold start.
    # Startup probe allows slow initialization without triggering
    # liveness/readiness failures during boot.
    # ============================================================
    startupProbe:
      httpGet:
        path: /health/readiness
        port: 4000
      # Allow up to 5 minutes for Prisma engine + migrations
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 30
      successThreshold: 1

    livenessProbe:
      httpGet:
        path: /health/liveliness
        port: 4000
      # Only checked after startupProbe succeeds
      initialDelaySeconds: 0
      periodSeconds: 15
      timeoutSeconds: 10
      failureThreshold: 3

    readinessProbe:
      httpGet:
        path: /health/readiness
        port: 4000
      # Only checked after startupProbe succeeds
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 3

    # ============================================================
    # Pod Disruption Budget
    # ============================================================
    podDisruptionBudget:
      enabled: true
      minAvailable: 1

    # ============================================================
    # Autoscaling
    # IMPORTANT: HPA behavior prevents rapid pod spinning when pods
    # fail during startup. Scale-up is stabilized over 3 minutes to
    # give failing pods time to recover or be properly terminated.
    # ============================================================
    autoscaling:
      enabled: true
      minReplicas: 2
      maxReplicas: 3
      # Use CPU only - memory spikes during failures cause feedback loops
      targetCPUUtilizationPercentage: 70
      # Disable memory-based scaling to prevent pod spinning
      # targetMemoryUtilizationPercentage: 80
      behavior:
        scaleUp:
          # Stabilize for 3 minutes before scaling up
          # Prevents rapid pod accumulation during cascading failures
          stabilizationWindowSeconds: 180
          policies:
            # Add at most 1 pod per minute
            - type: Pods
              value: 1
              periodSeconds: 60
            # Or 25% of current replicas, whichever is smaller
            - type: Percent
              value: 25
              periodSeconds: 60
          selectPolicy: Min
        scaleDown:
          # Wait 5 minutes before scaling down
          # Allows for traffic spikes without thrashing
          stabilizationWindowSeconds: 300
          policies:
            - type: Pods
              value: 1
              periodSeconds: 60

    # ============================================================
    # Security Context
    # The litellm-non_root image runs as non-root user (UID 1000).
    # readOnlyRootFilesystem must be false for /tmp writes needed
    # by Prisma binary cache.
    # ============================================================
    podSecurityContext:
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 1000
      fsGroup: 1000

    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
          - ALL

    # ============================================================
    # Pod Lifecycle
    # ============================================================
    # Allow time for graceful shutdown and connection draining
    terminationGracePeriodSeconds: 60

    # ============================================================
    # Pod Annotations (for Prometheus scraping)
    # ============================================================
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "4000"
      prometheus.io/path: "/metrics"
