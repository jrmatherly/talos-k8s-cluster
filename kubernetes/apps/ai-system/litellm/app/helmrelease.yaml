---
# yaml-language-server: $schema=https://raw.githubusercontent.com/bjw-s-labs/helm-charts/main/charts/other/app-template/schemas/helmrelease-helm-v2.schema.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
spec:
  chartRef:
    kind: OCIRepository
    name: litellm
  interval: 1h
  timeout: 15m
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
      remediateLastFailure: true

  values:
    # ==========================================================================
    # Default Pod Options
    # Security context with fsGroup ensures mounted volumes are writable
    # litellm-non_root image runs as UID 65534 (nobody)
    # ==========================================================================
    defaultPodOptions:
      securityContext:
        fsGroup: 65534
        fsGroupChangePolicy: OnRootMismatch
        seccompProfile:
          type: RuntimeDefault
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "4000"
        prometheus.io/path: "/metrics"
      terminationGracePeriodSeconds: 60

    # ==========================================================================
    # Controllers
    # ==========================================================================
    controllers:
      litellm:
        type: deployment
        replicas: 2
        strategy: RollingUpdate
        rollingUpdate:
          unavailable: 0
          surge: 1

        containers:
          app:
            image:
              # litellm-non_root image is designed for K8s non-root contexts
              # Pre-built Prisma binaries eliminate runtime npm install issues
              repository: ghcr.io/berriai/litellm-non_root
              tag: main-v1.80.5-stable.1
              pullPolicy: IfNotPresent

            args:
              - --host
              - "0.0.0.0"
              - --port
              - "4000"
              - --config
              - /app/config.yaml

            env:
              # Core LiteLLM settings
              TZ: "America/New_York"
              STORE_MODEL_IN_DB: "True"
              USE_PRISMA_MIGRATE: "True"
              LITELLM_MODE: "PRODUCTION"
              LITELLM_DONT_SHOW_FEEDBACK_BOX: "True"
              LITELLM_CALLBACKS: prometheus
              # Writable directory for database migrations (non-root support)
              LITELLM_MIGRATION_DIR: "/data/migrations"

              # Redis/Dragonfly settings
              REDIS_HOST: litellm-dragonfly
              REDIS_PORT: "6379"
              REDIS_NAMESPACE: litellm
              REDIS_URL:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: REDIS_URL

              # Database URL (constructed from secret)
              DATABASE_URL:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: DATABASE_URL

              # LiteLLM Master/Salt Keys
              LITELLM_MASTER_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: LITELLM_MASTER_KEY
              LITELLM_SALT_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: LITELLM_SALT_KEY

              # UI Authentication
              UI_USERNAME: admin
              UI_PASSWORD:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: LITELLM_MASTER_KEY

              # Redis Password
              REDIS_PASSWORD:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: REDIS_PASSWORD

              # Azure OpenAI US East
              AZURE_API_BASE: "https://aaronsai.openai.azure.com/"
              AZURE_API_VERSION: "2025-01-01-preview"
              AZURE_API_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: AZURE_API_KEY

              # Azure OpenAI US East2
              AZURE_API_BASE_EAST2: "https://ets-east-us2.openai.azure.com/"
              AZURE_API_VERSION_EAST2: "2025-04-01-preview"
              AZURE_API_KEY_EAST2:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: AZURE_API_KEY_EAST2

              # Azure Anthropic API
              AZURE_ANTHROPIC_API_BASE: "https://ets-east-us2.services.ai.azure.com/anthropic"
              AZURE_ANTHROPIC_API_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: AZURE_ANTHROPIC_API_KEY

              # Azure Cohere Rerank API
              AZURE_COHERE_RERANK_API_BASE: "https://aan-cohere-rerank-v3-5.eastus.models.ai.azure.com/v2/rerank"
              AZURE_COHERE_RERANK_API_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: AZURE_COHERE_RERANK_API_KEY

              # Azure Cohere Embed API
              AZURE_COHERE_EMBED_API_BASE: "https://aaronsai.services.ai.azure.com/models"
              AZURE_COHERE_EMBED_API_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: AZURE_COHERE_EMBED_API_KEY

              # Langfuse Observability
              LANGFUSE_HOST: "https://aiops.matherly.net"
              LANGFUSE_PUBLIC_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: LANGFUSE_PUBLIC_KEY
              LANGFUSE_SECRET_KEY:
                valueFrom:
                  secretKeyRef:
                    name: litellm-secret
                    key: LANGFUSE_SECRET_KEY

            probes:
              startup:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health/liveliness
                    port: &port 4000
                  # Extended startup time for Prisma initialization
                  initialDelaySeconds: 30
                  periodSeconds: 5
                  timeoutSeconds: 10
                  failureThreshold: 30
                  successThreshold: 1
              liveness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health/liveliness
                    port: *port
                  initialDelaySeconds: 60
                  periodSeconds: 15
                  timeoutSeconds: 10
                  failureThreshold: 3
              readiness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health/liveliness
                    port: *port
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  timeoutSeconds: 10
                  failureThreshold: 3

            securityContext:
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: false
              runAsUser: 65534
              runAsGroup: 65534
              runAsNonRoot: true
              privileged: false
              capabilities: { drop: ["ALL"] }
              seccompProfile: { type: RuntimeDefault }

            resources:
              requests:
                cpu: "500m"
                memory: "512Mi"
              limits:
                cpu: "2000m"
                memory: "2Gi"

    # ==========================================================================
    # Service
    # Service named 'litellm' to match existing HTTPRoute/ServiceMonitor refs
    # ==========================================================================
    service:
      litellm:
        controller: litellm
        ports:
          http:
            port: 4000
            targetPort: *port

    # ==========================================================================
    # Persistence
    # EmptyDir mounts for writable directories required by Prisma + npm
    # litellm-non_root uses /nonexistent as home directory for nobody user
    # ==========================================================================
    persistence:
      # LiteLLM config file from ConfigMap
      config-file:
        type: configMap
        name: litellm-config
        globalMounts:
          - path: /app/config.yaml
            subPath: config.yaml
            readOnly: true

      # Temp directory for ephemeral data
      tmp:
        type: emptyDir
        sizeLimit: 100Mi
        globalMounts:
          - path: /tmp

      # Prisma/Python cache directory
      cache:
        type: emptyDir
        sizeLimit: 500Mi
        globalMounts:
          - path: /.cache

      # npm cache directory for Prisma CLI
      npm-cache:
        type: emptyDir
        sizeLimit: 500Mi
        globalMounts:
          - path: /.npm

      # Prisma cache for nobody user (home dir is /nonexistent)
      nonexistent:
        type: emptyDir
        sizeLimit: 500Mi
        globalMounts:
          - path: /nonexistent

      # Migrations directory for LITELLM_MIGRATION_DIR
      data:
        type: emptyDir
        sizeLimit: 100Mi
        globalMounts:
          - path: /data
