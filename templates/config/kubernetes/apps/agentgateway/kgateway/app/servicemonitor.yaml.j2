#% if agentgateway_enabled and observability_enabled %#
---
#| ============================================= #|
#| ServiceMonitor: kgateway Control Plane        #|
#| ============================================= #|
#| Scrapes kgateway controller metrics on port 9092 #|
#| Metrics: reconciliation, xDS, translation, NACKs #|
#| Key metric: kgateway_agentgateway_xds_rejects_total (NACK detection) #|
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kgateway-control-plane
  labels:
    release: kube-prometheus-stack
spec:
  jobLabel: kgateway
  namespaceSelector:
    matchNames:
      - agentgateway
  endpoints:
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    honorLabels: true
    relabelings:
      - sourceLabels: [__meta_kubernetes_namespace]
        targetLabel: namespace
      - sourceLabels: [__meta_kubernetes_pod_name]
        targetLabel: pod
  selector:
    matchLabels:
      app.kubernetes.io/name: kgateway
---
#| Service for kgateway control plane metrics #|
#| Exposes port 9092 for Prometheus scraping #|
apiVersion: v1
kind: Service
metadata:
  name: kgateway-metrics
  labels:
    app.kubernetes.io/name: kgateway
spec:
  selector:
    app.kubernetes.io/name: kgateway
  ports:
  - name: metrics
    port: 9092
    targetPort: 9092
    protocol: TCP
  type: ClusterIP
---
#| ============================================= #|
#| ServiceMonitor: agentgateway Data Plane       #|
#| ============================================= #|
#| Scrapes agentgateway proxy stats on port 15020 #|
#| Metrics path: /stats/prometheus (Envoy-style stats) #|
#| Metrics: gen_ai token usage, request counts, latency #|
#| Key metric: agentgateway_gen_ai_client_token_usage #|
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: agentgateway
  labels:
    release: kube-prometheus-stack
spec:
  jobLabel: agentgateway
  namespaceSelector:
    matchNames:
      - agentgateway
  endpoints:
  - port: metrics
    path: /stats/prometheus
    interval: 30s
    scrapeTimeout: 10s
    honorLabels: true
    relabelings:
      #| Add namespace label #|
      - sourceLabels: [__meta_kubernetes_namespace]
        targetLabel: namespace
      #| Add pod name label #|
      - sourceLabels: [__meta_kubernetes_pod_name]
        targetLabel: pod
      #| Add gateway name label #|
      - sourceLabels: [__meta_kubernetes_pod_label_gateway_networking_k8s_io_gateway_name]
        targetLabel: gateway_name
  selector:
    matchLabels:
      app.kubernetes.io/name: agentgateway
      gateway.networking.k8s.io/gateway-name: agentgateway
---
#| ============================================= #|
#| PrometheusRule: kgateway Control Plane Alerts #|
#| ============================================= #|
#| Alerts for: NACKs, reconciliation failures, xDS issues #|
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kgateway-control-plane-alerts
  labels:
    release: kube-prometheus-stack
spec:
  groups:
    - name: kgateway.control-plane.rules
      rules:
        #| Alert when agentgateway rejects configuration (NACK) #|
        #| Critical: indicates misconfigured resources #|
        - alert: KgatewayConfigurationRejected
          expr: |
            increase(kgateway_agentgateway_xds_rejects_total[5m]) > 0
          for: 1m
          labels:
            severity: warning
          annotations:
            summary: "agentgateway proxy rejected configuration update"
            description: "The agentgateway data plane has rejected {{ $$value | humanize }} configuration updates in the last 5 minutes. Check Kubernetes events: kubectl get events -n agentgateway --field-selector=reason=AgentGatewayNackError"

        #| Alert when kgateway control plane is down #|
        - alert: KgatewayControlPlaneDown
          expr: |
            absent(up{job="kgateway"} == 1)
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "kgateway control plane is down"
            description: "The kgateway control plane has been unavailable for more than 5 minutes. Configuration updates will not propagate to agentgateway."

        #| Alert on high reconciliation error rate #|
        - alert: KgatewayReconciliationErrors
          expr: |
            sum(rate(kgateway_controller_reconciliations_total{result="error"}[5m])) > 0.1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "kgateway controller experiencing reconciliation errors"
            description: "The kgateway controller is failing to reconcile resources at {{ $$value | humanize }} errors/sec"

        #| Alert when resource updates are dropped #|
        #| Critical: All resource metrics become invalid when this occurs #|
        - alert: KgatewayResourceUpdatesDropped
          expr: |
            increase(kgateway_resources_updates_dropped_total[5m]) > 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "kgateway controller dropped resource updates"
            description: "CRITICAL: kgateway controller dropped resource updates. All resource metrics are now invalid. Restart the kgateway controller immediately: kubectl rollout restart deployment/kgateway -n agentgateway"

        #| Alert on xDS sync failures #|
        - alert: KgatewayXdsSyncFailures
          expr: |
            sum(rate(kgateway_xds_snapshot_syncs_total{result="error"}[5m])) > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "xDS snapshot sync failures detected"
            description: "kgateway is failing to sync xDS snapshots at {{ $$value | humanize }} errors/sec. agentgateway may have stale configuration."

        #| Alert on xDS authentication failures #|
        - alert: KgatewayXdsAuthFailures
          expr: |
            sum(rate(kgateway_xds_auth_rq_failure_total[5m])) > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "xDS authentication failures detected"
            description: "agentgateway data plane is failing to authenticate with kgateway control plane. Check NetworkPolicies and TLS configuration."
---
#| ============================================= #|
#| PrometheusRule: agentgateway Data Plane Alerts #|
#| ============================================= #|
#| Alerts for: gateway down, high error rate, cost, latency #|
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: agentgateway-alerts
  labels:
    release: kube-prometheus-stack
spec:
  groups:
    - name: agentgateway.rules
      rules:
        #| Alert when agentgateway is down #|
        - alert: AgentgatewayDown
          expr: |
            absent(up{job="agentgateway"} == 1)
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "agentgateway is down"
            description: "The agentgateway has been unavailable for more than 5 minutes. AI traffic routing is offline."

        #| Alert on high error rate #|
        - alert: AgentgatewayHighErrorRate
          expr: |
            sum(rate(agentgateway_requests_total{status=~"5.."}[5m])) by (gateway_name)
            /
            sum(rate(agentgateway_requests_total[5m])) by (gateway_name)
            > 0.05
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High error rate on agentgateway (>5%)"
            description: "Gateway {{ $$labels.gateway_name }} has {{ $$value | humanizePercentage }} error rate over the last 5 minutes"

        #| Alert when daily AI cost exceeds threshold #|
        - alert: AgentgatewayDailyCostHigh
          expr: |
            sum(agentgateway_cost_usd_daily) by (gateway_name) > 100
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Daily AI cost exceeds $100"
            description: "Gateway {{ $$labels.gateway_name }} has incurred $${{ $$value | humanize }} in AI costs today"

        #| Alert when token budget is exceeded #|
        - alert: AgentgatewayTokenBudgetExceeded
          expr: |
            sum(increase(agentgateway_input_tokens_total[24h])) by (gateway_name) > 1000000
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Daily token usage exceeds 1M tokens"
            description: "Gateway {{ $$labels.gateway_name }} has processed {{ $$value | humanize }} tokens in the last 24 hours"

        #| Alert on high P99 latency #|
        - alert: AgentgatewayHighLatency
          expr: |
            histogram_quantile(0.99,
              sum(rate(agentgateway_request_duration_seconds_bucket[5m])) by (le, gateway_name)
            ) > 10
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "High latency for agentgateway (P99 > 10s)"
            description: "Gateway {{ $$labels.gateway_name }} P99 latency is {{ $$value | humanizeDuration }}"

        #| Alert when prompt guards are frequently triggered #|
        - alert: AgentgatewayFrequentPromptGuardBlocks
          expr: |
            sum(rate(agentgateway_prompt_guard_blocks_total[5m])) by (gateway_name, pattern) > 1
          for: 10m
          labels:
            severity: info
          annotations:
            summary: "Frequent prompt guard blocks detected"
            description: "Gateway {{ $$labels.gateway_name }} is blocking {{ $$value | humanize }} requests/sec due to {{ $$labels.pattern }} pattern"

        #| Alert when rate limiting is frequently applied #|
        - alert: AgentgatewayRateLimitActive
          expr: |
            sum(rate(agentgateway_rate_limit_exceeded_total[5m])) by (gateway_name) > 5
          for: 10m
          labels:
            severity: info
          annotations:
            summary: "Rate limiting is actively rejecting requests"
            description: "Gateway {{ $$labels.gateway_name }} is rate limiting {{ $$value | humanize }} requests/sec. Consider increasing limits."

        #| Alert on per-model cost anomalies #|
        - alert: AgentgatewayModelCostAnomaly
          expr: |
            sum(rate(agentgateway_cost_usd_total[1h])) by (model, gateway_name)
            >
            1.5 * avg_over_time(sum(rate(agentgateway_cost_usd_total[1h])) by (model, gateway_name)[7d:1h])
          for: 30m
          labels:
            severity: warning
          annotations:
            summary: "Model {{ $$labels.model }} cost is 50% higher than 7-day average"
            description: "Gateway {{ $$labels.gateway_name }} model {{ $$labels.model }} hourly cost is anomalously high"
---
#| ============================================= #|
#| PrometheusRule: FinOps Recording Rules        #|
#| ============================================= #|
#| Recording rules for token usage and cost aggregation #|
#| Used by the AgentGateway FinOps dashboard #|
#| Cost model: Azure OpenAI pricing (adjust for your provider) #|
#|   - Input tokens: $0.0015 per 1K tokens (gpt-4.1-mini) #|
#|   - Output tokens: $0.006 per 1K tokens (gpt-4.1-mini) #|
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: agentgateway-finops-recording-rules
  labels:
    release: kube-prometheus-stack
spec:
  groups:
    - name: agentgateway.finops.recording_rules
      interval: 30s
      rules:
        #| ===== Token Usage Recording Rules ===== #|
        #| Total input tokens processed (5m window) #|
        - record: agentgateway:input_tokens:total
          expr: |
            sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[5m])) or vector(0)

        #| Total output tokens generated (5m window) #|
        - record: agentgateway:output_tokens:total
          expr: |
            sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[5m])) or vector(0)

        #| Input tokens by gateway (for per-gateway tracking) #|
        - record: agentgateway:input_tokens:by_gateway
          expr: |
            sum by (gateway_name) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[5m])) or vector(0)

        #| Output tokens by gateway (for per-gateway tracking) #|
        - record: agentgateway:output_tokens:by_gateway
          expr: |
            sum by (gateway_name) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[5m])) or vector(0)

        #| ===== Cost Recording Rules ===== #|
        #| Hourly cost per gateway (Azure OpenAI GPT-4.1-mini pricing) #|
        #| Formula: (input_tokens * $0.0015/1K) + (output_tokens * $0.006/1K) #|
        - record: agentgateway:cost_usd:by_gateway
          expr: |
            (
              sum by (gateway_name) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[1h])) / 1000 * 0.0015
              +
              sum by (gateway_name) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[1h])) / 1000 * 0.006
            ) or vector(0)

        #| Total hourly cost (all gateways) #|
        - record: agentgateway:cost_usd:total_hourly
          expr: |
            (
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[1h])) / 1000 * 0.0015
              +
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[1h])) / 1000 * 0.006
            ) or vector(0)

        #| Total daily cost (24h rolling window) #|
        - record: agentgateway:cost_usd:total_daily
          expr: |
            (
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[24h])) / 1000 * 0.0015
              +
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[24h])) / 1000 * 0.006
            ) or vector(0)

        #| Total weekly cost (7d rolling window) #|
        - record: agentgateway:cost_usd:total_weekly
          expr: |
            (
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[7d])) / 1000 * 0.0015
              +
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[7d])) / 1000 * 0.006
            ) or vector(0)

        #| Total monthly cost (30d rolling window) #|
        - record: agentgateway:cost_usd:total_monthly
          expr: |
            (
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[30d])) / 1000 * 0.0015
              +
              sum(increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[30d])) / 1000 * 0.006
            ) or vector(0)

        #| ===== Model-specific cost tracking ===== #|
        #| Cost by model (for multi-model deployments) #|
        - record: agentgateway:cost_usd:by_model
          expr: |
            (
              sum by (gen_ai_request_model) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="input"}[1h])) / 1000 * 0.0015
              +
              sum by (gen_ai_request_model) (increase(agentgateway_gen_ai_client_token_usage_sum{gen_ai_token_type="output"}[1h])) / 1000 * 0.006
            ) or vector(0)
#% endif %#