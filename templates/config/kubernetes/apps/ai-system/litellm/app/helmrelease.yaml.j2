#% if litellm_enabled %#
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
spec:
  chartRef:
    kind: OCIRepository
    name: litellm
  interval: 1h
  timeout: 15m
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    cleanupOnFail: true
    remediation:
      retries: 3
      remediateLastFailure: true
  # Skip Helm tests - chart has bug in test-env-vars.yaml expecting DD_* vars
  test:
    enable: false
  values:
    # ============================================================
    # Image Configuration
    # ============================================================
    image:
      repository: ghcr.io/berriai/litellm
      tag: main-stable
      pullPolicy: IfNotPresent

    # ============================================================
    # Replica Configuration (HPA handles scaling)
    # ============================================================
    replicaCount: #{ litellm_replicas_min }#

    # ============================================================
    # Resource Configuration
    # ============================================================
    resources:
      requests:
        cpu: "#{ litellm_cpu_request }#"
        memory: "#{ litellm_memory_request }#"
      limits:
        cpu: "#{ litellm_cpu_limit }#"
        memory: "#{ litellm_memory_limit }#"

    # ============================================================
    # Service Configuration
    # ============================================================
    service:
      type: ClusterIP
      port: 4000

    # ============================================================
    # Database Configuration (use external CloudNativePG)
    # ============================================================
    db:
      useExisting: true
      deployStandalone: false
      endpoint: litellm-db-rw
      database: litellm
      secret:
        name: litellm-db-secret
        usernameKey: username
        passwordKey: password

    # ============================================================
    # Migration Job Configuration
    # ============================================================
    migrationJob:
      enabled: false  # Disable - has permission issues with non-root

    # ============================================================
    # Environment Variables (simple key-value map)
    # ============================================================
    envVars:
      STORE_MODEL_IN_DB: "true"
      REDIS_HOST: "litellm-dragonfly"
      REDIS_PORT: "6379"
      REDIS_NAMESPACE: "litellm"
#% if azure_openai_us_east_api_key %#
      AZURE_API_BASE: "https://#{ azure_openai_us_east_resource_name }#.openai.azure.com"
      AZURE_API_VERSION: "2024-10-01-preview"
#% endif %#
#% if azure_openai_us_east2_api_key %#
      AZURE_API_BASE_EAST2: "https://#{ azure_openai_us_east2_resource_name }#.openai.azure.com"
      AZURE_API_VERSION_EAST2: "2024-10-01-preview"
      AZURE_ANTHROPIC_API_BASE: "https://#{ azure_openai_us_east2_resource_name }#.models.ai.azure.com"
#% endif %#
#% if litellm_langfuse_enabled %#
      LANGFUSE_HOST: "#{ litellm_langfuse_host }#"
#% endif %#

    # ============================================================
    # Extra Environment Variables (K8s env spec with secretKeyRef)
    # ============================================================
    extraEnvVars:
      - name: LITELLM_MASTER_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_MASTER_KEY
      - name: LITELLM_SALT_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_SALT_KEY

      # Redis/Dragonfly Cache Password
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: REDIS_PASSWORD

#% if azure_openai_us_east_api_key %#
      # Azure OpenAI US East
      - name: AZURE_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY
#% endif %#

#% if azure_openai_us_east2_api_key %#
      # Azure OpenAI US East2
      - name: AZURE_API_KEY_EAST2
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY_EAST2
#% endif %#

#% if litellm_langfuse_enabled %#
      # Langfuse Observability
      - name: LANGFUSE_PUBLIC_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_PUBLIC_KEY
      - name: LANGFUSE_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_SECRET_KEY
#% endif %#

    # ============================================================
    # Config File (mounted from ConfigMap)
    # ============================================================
    litellm_config:
      existingConfigMapName: litellm-config

    # ============================================================
    # Additional Volumes (for non-root user cache and npm)
    # ============================================================
    volumes:
      - name: cache
        emptyDir: {}
      - name: npm-cache
        emptyDir: {}
    volumeMounts:
      - name: cache
        mountPath: "/.cache"
      - name: npm-cache
        mountPath: "/.npm"

    # ============================================================
    # Probes Configuration
    # ============================================================
    livenessProbe:
      httpGet:
        path: /health/liveliness
        port: 4000
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3

    readinessProbe:
      httpGet:
        path: /health/readiness
        port: 4000
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3

    # ============================================================
    # Pod Disruption Budget
    # ============================================================
    podDisruptionBudget:
      enabled: true
      minAvailable: 1

    # ============================================================
    # Autoscaling
    # ============================================================
    autoscaling:
      enabled: true
      minReplicas: #{ litellm_replicas_min }#
      maxReplicas: #{ litellm_replicas_max }#
      targetCPUUtilizationPercentage: 70
      targetMemoryUtilizationPercentage: 80

    # ============================================================
    # Security Context
    # ============================================================
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
      runAsGroup: 1000
      fsGroup: 1000

    containerSecurityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
          - ALL

    # ============================================================
    # Pod Annotations (for Prometheus scraping)
    # ============================================================
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "4000"
      prometheus.io/path: "/metrics"
#% endif %#
