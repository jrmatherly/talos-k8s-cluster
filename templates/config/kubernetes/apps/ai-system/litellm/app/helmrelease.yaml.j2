#% if litellm_enabled %#
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: litellm
spec:
  chartRef:
    kind: OCIRepository
    name: litellm
  interval: 1h
  timeout: 15m
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    crds: CreateReplace
    cleanupOnFail: true
    remediation:
      retries: 3
      remediateLastFailure: true
  # Skip Helm tests - chart has bug in test-env-vars.yaml expecting DD_* vars
  test:
    enable: false
  values:
    # ============================================================
    # Image Configuration
    # IMPORTANT: Use litellm-database image from Docker Hub which
    # includes pre-built Prisma binaries and database tools.
    # ghcr.io images have Prisma/wolfi compatibility issues.
    # See: https://github.com/BerriAI/litellm/issues/17093
    # ============================================================
    image:
      # Docker Hub litellm-database image with pre-built Prisma binaries
      repository: litellm/litellm-database
      tag: v1.80.5-stable.1
      pullPolicy: IfNotPresent

    # ============================================================
    # Replica Configuration (HPA handles scaling)
    # ============================================================
    replicaCount: #{ litellm_replicas_min }#

    # ============================================================
    # Deployment Strategy
    # Conservative RollingUpdate prevents cascading failures during
    # slow startups with Prisma engine initialization
    # ============================================================
    strategy:
      type: RollingUpdate
      rollingUpdate:
        # Only surge by 1 pod at a time to limit failed pod accumulation
        maxSurge: 1
        # Keep at least 50% available during updates
        maxUnavailable: 0

    # ============================================================
    # Resource Configuration
    # ============================================================
    resources:
      requests:
        cpu: "#{ litellm_cpu_request }#"
        memory: "#{ litellm_memory_request }#"
      limits:
        cpu: "#{ litellm_cpu_limit }#"
        memory: "#{ litellm_memory_limit }#"

    # ============================================================
    # Service Configuration
    # ============================================================
    service:
      type: ClusterIP
      port: 4000

    # ============================================================
    # Database Configuration (use external CloudNativePG)
    # ============================================================
    db:
      useExisting: true
      deployStandalone: false
      endpoint: litellm-db-rw
      database: litellm
      secret:
        name: litellm-db-secret
        usernameKey: username
        passwordKey: password

    # ============================================================
    # Migration Job Configuration
    # ============================================================
    migrationJob:
      enabled: false  # Disable - has permission issues with non-root

    # ============================================================
    # Environment Variables (simple key-value map)
    # ============================================================
    envVars:
      STORE_MODEL_IN_DB: "true"
      REDIS_HOST: "litellm-dragonfly"
      REDIS_PORT: "6379"
      REDIS_NAMESPACE: "litellm"
      LITELLM_MIGRATION_DIR: "/tmp"
      LITELLM_CALLBACKS: "prometheus"
#% if azure_openai_us_east_api_key %#
      AZURE_API_BASE: "https://#{ azure_openai_us_east_resource_name }#.openai.azure.com/"
      AZURE_API_VERSION: "2025-01-01-preview"
#% endif %#
#% if azure_openai_us_east2_api_key %#
      AZURE_API_BASE_EAST2: "https://#{ azure_openai_us_east2_resource_name }#.openai.azure.com/"
      AZURE_API_VERSION_EAST2: "2025-04-01-preview"
#% endif %#
#% if azure_anthropic_api_base %#
      AZURE_ANTHROPIC_API_BASE: "#{ azure_anthropic_api_base }#"
#% endif %#
#% if azure_cohere_rerank_api_base %#
      AZURE_COHERE_RERANK_API_BASE: "#{ azure_cohere_rerank_api_base }#"
#% endif %#
#% if azure_cohere_embed_api_base %#
      AZURE_COHERE_EMBED_API_BASE: "#{ azure_cohere_embed_api_base }#"
#% endif %#
#% if litellm_langfuse_enabled %#
      LANGFUSE_HOST: "#{ litellm_langfuse_host }#"
#% endif %#

    # ============================================================
    # Extra Environment Variables (K8s env spec with secretKeyRef)
    # ============================================================
    extraEnvVars:
      - name: LITELLM_MASTER_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_MASTER_KEY
      - name: LITELLM_SALT_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_SALT_KEY

      # UI Authentication (default: admin / MASTER_KEY)
      - name: UI_USERNAME
        value: "admin"
      - name: UI_PASSWORD
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LITELLM_MASTER_KEY

      # Redis/Dragonfly Cache Password
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: REDIS_PASSWORD

#% if azure_openai_us_east_api_key %#
      # Azure OpenAI US East
      - name: AZURE_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY
#% endif %#

#% if azure_openai_us_east2_api_key %#
      # Azure OpenAI US East2
      - name: AZURE_API_KEY_EAST2
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_API_KEY_EAST2
#% endif %#

#% if azure_cohere_rerank_api_key %#
      # Azure Cohere Rerank API
      - name: AZURE_COHERE_RERANK_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_COHERE_RERANK_API_KEY
#% endif %#

#% if azure_cohere_embed_api_key %#
      # Azure Cohere Embed API
      - name: AZURE_COHERE_EMBED_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_COHERE_EMBED_API_KEY
#% endif %#

#% if azure_anthropic_api_key %#
      # Azure Anthropic API (Claude models via Azure AI)
      - name: AZURE_ANTHROPIC_API_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: AZURE_ANTHROPIC_API_KEY
#% endif %#

#% if litellm_langfuse_enabled %#
      # Langfuse Observability
      - name: LANGFUSE_PUBLIC_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_PUBLIC_KEY
      - name: LANGFUSE_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: litellm-secret
            key: LANGFUSE_SECRET_KEY
#% endif %#

    # ============================================================
    # Config File (mounted from ConfigMap)
    # ============================================================
    proxyConfigMap:
      create: false
      name: litellm-config
      key: config.yaml

    # ============================================================
    # Probes Configuration
    # Prisma engine initialization can take 30-60s on cold start.
    # Startup probe allows slow initialization without triggering
    # liveness/readiness failures during boot.
    # ============================================================
    startupProbe:
      httpGet:
        path: /health/readiness
        port: 4000
      # Allow up to 5 minutes for Prisma engine + migrations
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 30
      successThreshold: 1

    livenessProbe:
      httpGet:
        path: /health/liveliness
        port: 4000
      # Only checked after startupProbe succeeds
      initialDelaySeconds: 0
      periodSeconds: 15
      timeoutSeconds: 10
      failureThreshold: 3

    readinessProbe:
      httpGet:
        path: /health/readiness
        port: 4000
      # Only checked after startupProbe succeeds
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 3

    # ============================================================
    # Pod Disruption Budget
    # ============================================================
    podDisruptionBudget:
      enabled: true
      minAvailable: 1

    # ============================================================
    # Autoscaling
    # IMPORTANT: HPA behavior prevents rapid pod spinning when pods
    # fail during startup. Scale-up is stabilized over 3 minutes to
    # give failing pods time to recover or be properly terminated.
    # ============================================================
    autoscaling:
      enabled: true
      minReplicas: #{ litellm_replicas_min }#
      maxReplicas: #{ litellm_replicas_max }#
      # Use CPU only - memory spikes during failures cause feedback loops
      targetCPUUtilizationPercentage: 70
      # Disable memory-based scaling to prevent pod spinning
      # targetMemoryUtilizationPercentage: 80
      behavior:
        scaleUp:
          # Stabilize for 3 minutes before scaling up
          # Prevents rapid pod accumulation during cascading failures
          stabilizationWindowSeconds: 180
          policies:
            # Add at most 1 pod per minute
            - type: Pods
              value: 1
              periodSeconds: 60
            # Or 25% of current replicas, whichever is smaller
            - type: Percent
              value: 25
              periodSeconds: 60
          selectPolicy: Min
        scaleDown:
          # Wait 5 minutes before scaling down
          # Allows for traffic spikes without thrashing
          stabilizationWindowSeconds: 300
          policies:
            - type: Pods
              value: 1
              periodSeconds: 60

    # ============================================================
    # Security Context
    # Standard litellm image requires root for Prisma binary generation
    # on first run. readOnlyRootFilesystem must be false for /tmp writes.
    # ============================================================
    podSecurityContext:
      # Standard image runs as root (UID 0)
      runAsNonRoot: false
      fsGroup: 0

    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: false
      # Standard image needs root for Prisma
      runAsNonRoot: false
      runAsUser: 0
      capabilities:
        drop:
          - ALL
        add:
          # Required for network operations
          - NET_BIND_SERVICE

    # ============================================================
    # Pod Lifecycle
    # ============================================================
    # Allow time for graceful shutdown and connection draining
    terminationGracePeriodSeconds: 60

    # ============================================================
    # Pod Annotations (for Prometheus scraping)
    # ============================================================
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "4000"
      prometheus.io/path: "/metrics"
#% endif %#
