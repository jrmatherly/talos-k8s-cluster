#% if litellm_enabled %#
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
data:
  config.yaml: |
    # LiteLLM Configuration - Bootstrap Config
    # Models are stored in database (STORE_MODEL_IN_DB=true) for runtime management
    # This config provides initial bootstrap settings and general configuration

    # Model Definitions (Bootstrap - can be modified via API)
    model_list:
#% if azure_openai_us_east_api_key %#
      # Azure OpenAI US East Models
      - model_name: gpt-4.1
        litellm_params:
          model: azure/gpt-4.1
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 13107
          rpm: 250
          tpm: 250000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: gpt-4.1

      - model_name: gpt-4.1-nano
        litellm_params:
          model: azure/gpt-4.1-nano
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 13107
          rpm: 450
          tpm: 450000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["default-models"]
          base_model: gpt-4.1-nano

      - model_name: gpt-4o-mini
        litellm_params:
          model: azure/gpt-4o-mini
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 4096
          rpm: 5000
          tpm: 500000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["default-models"]
          base_model: gpt-4o-mini

      - model_name: o3
        litellm_params:
          model: azure/o3
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 40000
          thinking:
            type: enabled
            budget_tokens: 4096
          merge_reasoning_content_in_choices: true
          rpm: 250
          tpm: 250000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: o3

      - model_name: o4-mini
        litellm_params:
          model: azure/o4-mini
          litellm_credential_name: azure_credential_us_east
          max_completion_tokens: 40000
          thinking:
            type: enabled
            budget_tokens: 8192
          merge_reasoning_content_in_choices: true
          rpm: 2000
          tpm: 400000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: o4-mini

      - model_name: text-embedding-3-small
        litellm_params:
          model: azure/text-embedding-3-small
          litellm_credential_name: azure_credential_us_east
          rpm: 3000
          tpm: 500000
        model_info:
          mode: embedding
          access_groups: ["default-models"]
          base_model: text-embedding-3-small

      - model_name: text-embedding-ada-002
        litellm_params:
          model: azure/text-embedding-ada-002
          litellm_credential_name: azure_credential_us_east
          rpm: 3000
          tpm: 500000
        model_info:
          mode: embedding
          access_groups: ["default-models"]
          base_model: text-embedding-ada-002
#% endif %#

#% if azure_openai_us_east2_api_key %#
      # Azure OpenAI US East2 Models
      - model_name: gpt-5
        litellm_params:
          model: azure/gpt-5
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 1750
          tpm: 1750000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: gpt-5

      - model_name: gpt-5-mini
        litellm_params:
          model: azure/gpt-5-mini
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 2500
          tpm: 2500000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["default-models"]
          base_model: gpt-5-mini

      - model_name: gpt-5-nano
        litellm_params:
          model: azure/gpt-5-nano
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 15000
          tpm: 15000000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["default-models"]
          base_model: gpt-5-nano

      - model_name: gpt-5.1
        litellm_params:
          model: azure/gpt-5.1
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 20000
          tpm: 2000000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]
          base_model: gpt-5.1

      - model_name: gpt-5.1-codex
        litellm_params:
          model: azure/gpt-5.1-codex
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 2000
          tpm: 2000000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: gpt-5.1-codex

      - model_name: gpt-5.1-codex-mini
        litellm_params:
          model: azure/gpt-5.1-codex-mini
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 2500
          tpm: 2500000
          timeout: 300
          stream_timeout: 300
        model_info:
          access_groups: ["premium-models"]
          base_model: gpt-5.1-codex-mini

      - model_name: gpt-5.2
        litellm_params:
          model: azure/gpt-5.2
          litellm_credential_name: azure_credential_us_east2
          max_completion_tokens: 16384
          rpm: 22500
          tpm: 2250000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]
          base_model: gpt-5.2

      # Anthropic via Azure (Claude models)
      - model_name: claude-opus-4-5
        litellm_params:
          model: anthropic/claude-opus-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 1500
          tpm: 1500000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]

      - model_name: claude-sonnet-4-5
        litellm_params:
          model: anthropic/claude-sonnet-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 2750
          tpm: 2750000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]

      - model_name: claude-opus-4-1
        litellm_params:
          model: anthropic/claude-opus-4-1
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 1250
          tpm: 1250000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]

      - model_name: claude-haiku-4-5
        litellm_params:
          model: anthropic/claude-haiku-4-5
          litellm_credential_name: azure_credential_anthropic_us_east2
          max_completion_tokens: 16384
          rpm: 2250
          tpm: 2250000
          timeout: 300
          stream_timeout: 300
        model_info:
          supports_reasoning: true
          access_groups: ["premium-models"]

      - model_name: text-embedding-3-large
        litellm_params:
          model: azure/text-embedding-3-large
          litellm_credential_name: azure_credential_us_east2
          rpm: 18000
          tpm: 3000000
        model_info:
          mode: embedding
          access_groups: ["default-models"]
          base_model: text-embedding-3-large
#% endif %#

    # Credential List
    credential_list:
#% if azure_openai_us_east_api_key %#
      - credential_name: azure_credential_us_east
        credential_values:
          api_key: os.environ/AZURE_API_KEY
          api_base: os.environ/AZURE_API_BASE
          api_version: os.environ/AZURE_API_VERSION
        credential_info:
          description: "Azure OpenAI US East credentials"
#% endif %#
#% if azure_openai_us_east2_api_key %#
      - credential_name: azure_credential_us_east2
        credential_values:
          api_key: os.environ/AZURE_API_KEY_EAST2
          api_base: os.environ/AZURE_API_BASE_EAST2
          api_version: os.environ/AZURE_API_VERSION_EAST2
        credential_info:
          description: "Azure OpenAI US East2 credentials"
      - credential_name: azure_credential_anthropic_us_east2
        credential_values:
          api_key: os.environ/AZURE_API_KEY_EAST2
          api_base: os.environ/AZURE_ANTHROPIC_API_BASE
        credential_info:
          description: "Azure Anthropic US East2 credentials"
#% endif %#

    # LiteLLM Settings
    litellm_settings:
      drop_params: true
      max_budget: 1000
      budget_duration: 30d
      track_cost_per_model: true
      request_timeout: 600
      redact_messages_in_exceptions: true
      telemetry: false
      tpm_limit: 3500000
      rpm_limit: 35000
      max_file_size_mb: 25
      set_verbose: false
      json_logs: true

      # Fallback Logic
      fallbacks:
        - gpt-5.2:
            - gpt-5.1
            - gpt-5
        - gpt-5.1:
            - gpt-5
            - gpt-5-mini

      # Caching
      cache: true
      cache_params:
        type: redis
        host: os.environ/REDIS_HOST
        port: os.environ/REDIS_PORT
        password: os.environ/REDIS_PASSWORD
        namespace: os.environ/REDIS_NAMESPACE
        ttl: 600
        mode: default_on
        supported_call_types:
          - completion
          - acompletion
          - embedding
          - aembedding

      # Callbacks
      service_callback:
        - prometheus_system
      success_callback:
        - prometheus
#% if litellm_langfuse_enabled %#
        - langfuse
#% endif %#
      failure_callback:
        - prometheus
#% if litellm_langfuse_enabled %#
        - langfuse
#% endif %#

#% if litellm_langfuse_enabled %#
      # Langfuse Settings
      langfuse_host: os.environ/LANGFUSE_HOST
      langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
      langfuse_secret: os.environ/LANGFUSE_SECRET_KEY
      langfuse_enabled: true
      langfuse_sample_rate: 1.0
#% endif %#

    # Router Settings
    router_settings:
      routing_strategy: simple-shuffle
      redis_host: os.environ/REDIS_HOST
      redis_port: os.environ/REDIS_PORT
      redis_password: os.environ/REDIS_PASSWORD
      enable_pre_call_checks: true
      allowed_fails: 3
      cooldown_time: 30
      retry_policy:
        AuthenticationErrorRetries: 0
        TimeoutErrorRetries: 3
        RateLimitErrorRetries: 5
        InternalServerErrorRetries: 3
        ContentPolicyViolationErrorRetries: 0

    # General Settings
    general_settings:
      master_key: os.environ/LITELLM_MASTER_KEY
      database_url: os.environ/DATABASE_URL
      database_connection_pool_limit: 50
      database_connection_timeout: 60
      store_model_in_db: os.environ/STORE_MODEL_IN_DB
      proxy_batch_write_at: 60
      maximum_spend_logs_retention_period: "35d"
      maximum_spend_logs_retention_interval: "1d"
      allow_requests_on_db_unavailable: true
#% if litellm_mcp_enabled %#
      mcp_client_side_auth_header_name: "authorization"
#% endif %#
#% endif %#
