#% if ai_gateway_enabled and ai_gateway_azure_deployments %#
---
# AIGatewayRoute for Azure AI model routing
# Note: In v0.4.0, when group is specified in backendRefs, only InferencePool is supported.
#       For AIServiceBackend, omit group and kind fields - they default correctly.
apiVersion: aigateway.envoyproxy.io/v1alpha1
kind: AIGatewayRoute
metadata:
  name: azure-ai
spec:
  parentRefs:
    - name: ai-gateway
      kind: Gateway
      group: gateway.networking.k8s.io
#% if ai_gateway_ratelimit_enabled %#
  # Token usage tracking for rate limiting
  # These metadata keys are used by BackendTrafficPolicy to enforce token-based limits
  llmRequestCosts:
    - metadataKey: llm_input_token
      type: InputToken
    - metadataKey: llm_output_token
      type: OutputToken
    - metadataKey: llm_total_token
      type: TotalToken
#% endif %#
  rules:
#% for deployment in ai_gateway_azure_deployments %#
#% for model in deployment.models %#
    # Route for model: #{ model }# via deployment: #{ deployment.name }#
    - matches:
        - headers:
            - type: Exact
              name: x-ai-eg-model
              value: #{ model }#
      backendRefs:
        - name: azure-#{ deployment.name }#
#% endfor %#
#% endfor %#
#% endif %#
