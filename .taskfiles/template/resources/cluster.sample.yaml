---
# ==============================================================================
# CLUSTER CONFIGURATION
# ==============================================================================
# This file defines the core settings for your Talos Kubernetes cluster.
# Fill in the REQUIRED fields and optionally customize the others.
#
# TIP: Use 'task configure' to validate and render your configuration.
# ==============================================================================

# ==============================================================================
# NETWORK CONFIGURATION
# ==============================================================================

# -- The network CIDR that contains your node IP addresses.
#    This is the subnet where your Talos nodes will be assigned IPs.
#    (REQUIRED)
#    Example: "192.168.1.0/24" for a typical home network
#    Example: "10.0.0.0/24" for a private network
node_cidr: ""

# -- DNS servers for the Talos nodes to use for external resolution.
#    These are used by the nodes themselves, not for cluster DNS.
#    Public DNS servers from this list are also used as fallback for k8s_gateway.
#    (OPTIONAL) / (DEFAULT: ["1.1.1.1", "1.0.0.1"] - Cloudflare DNS)
#    Example: ["192.168.1.1", "1.1.1.1"] - Local router + Cloudflare
#    Example: ["172.64.36.x", "172.64.36.x"] - Cloudflare for Personal Resolvers
# node_dns_servers: []

# -- NTP servers for time synchronization on Talos nodes.
#    Accurate time is critical for certificate validation and cluster operations.
#    (OPTIONAL) / (DEFAULT: ["162.159.200.1", "162.159.200.123"] - Cloudflare NTP)
# node_ntp_servers: []

# -- The default gateway (router) IP for the nodes.
#    (OPTIONAL) / (DEFAULT: First usable IP in node_cidr, e.g., .1)
#    Only set this if your gateway is NOT the first IP in your subnet.
#    Example: "192.168.1.254" if your router uses .254 instead of .1
# node_default_gateway: ""

# -- VLAN tag for Talos node network interfaces.
#    Only needed if your nodes are on a tagged VLAN and your switch ports are NOT tagged.
#    (OPTIONAL) / (REF: https://www.talos.dev/latest/advanced/advanced-networking/#vlans)
#    Example: "100" for VLAN ID 100
# node_vlan_tag: ""

# ==============================================================================
# KUBERNETES CLUSTER SETTINGS
# ==============================================================================

# -- Virtual IP address for the Kubernetes API server.
#    This IP is shared across control plane nodes for high availability.
#    (REQUIRED) - Must be an UNUSED IP within node_cidr
#    TIP: Choose an IP outside the range you'll assign to nodes.
#    Example: If nodes are .101-.106, use .100 for the API
cluster_api_addr: ""

# -- Additional hostnames/IPs to include in the API server certificate.
#    Useful if you want to access the cluster by hostname or external IP.
#    (OPTIONAL)
#    Example: ["k8s.example.com", "192.168.1.200"]
# cluster_api_tls_sans: []

# -- Pod network CIDR for internal pod-to-pod communication.
#    Must NOT overlap with node_cidr or cluster_svc_cidr.
#    (OPTIONAL) / (DEFAULT: "10.42.0.0/16" - 65,536 pod IPs)
#    WARNING: Changing this after cluster creation requires a full rebuild.
# cluster_pod_cidr: ""

# -- Service network CIDR for Kubernetes ClusterIP services.
#    Must NOT overlap with node_cidr or cluster_pod_cidr.
#    (OPTIONAL) / (DEFAULT: "10.43.0.0/16" - 65,536 service IPs)
#    WARNING: Changing this after cluster creation requires a full rebuild.
# cluster_svc_cidr: ""

# ==============================================================================
# LOAD BALANCER IPS (Cilium L2/BGP Announcements)
# ==============================================================================
# These IPs are announced by Cilium and used for LoadBalancer services.
# All must be UNUSED IPs within node_cidr.

# -- IP for k8s_gateway DNS service (internal DNS resolution).
#    Configure your router/DNS server to forward your domain queries here.
#    This enables split-DNS so internal services resolve to internal IPs.
#    (REQUIRED) - Must be an UNUSED IP within node_cidr
#    TIP: See docs/udm-split-dns.md for router configuration examples.
cluster_dns_gateway_addr: ""

# -- IP for the internal ingress gateway (internal).
#    Used for services only accessible from your local network.
#    (REQUIRED) - Must be an UNUSED IP within node_cidr
cluster_gateway_addr: ""

# -- IP for the external ingress gateway (external via Cloudflare Tunnel).
#    Used for services accessible from the public internet.
#    (REQUIRED) - Must be an UNUSED IP within node_cidr
cloudflare_gateway_addr: ""

# -- Load balancer IP for the MCP Gateway.
#    (REQUIRED if mcp_gateway_enabled) - Must be an UNUSED IP within node_cidr
#    Example: "192.168.1.146"
# mcp_gateway_addr: ""

# ==============================================================================
# GITHUB REPOSITORY SETTINGS
# ==============================================================================

# -- Your GitHub repository in "owner/repo" format.
#    This is where Flux will sync cluster state from.
#    (REQUIRED)
#    Example: "myusername/my-k8s-cluster"
repository_name: ""

# -- Git branch for Flux to monitor.
#    (OPTIONAL) / (DEFAULT: "main")
# repository_branch: ""

# -- Repository visibility setting.
#    (OPTIONAL) / (DEFAULT: "public")
#    NOTE: If "private", you must add github-deploy.key.pub to your repo's deploy keys.
#    See README for detailed instructions.
# repository_visibility: ""

# ==============================================================================
# CLOUDFLARE SETTINGS
# ==============================================================================

# -- Your Cloudflare domain(s) for the cluster.
#    Can be a single domain string or an array of domains.
#    First domain is primary (used for flux-webhook, internal infrastructure).
#    (REQUIRED)
#    Single domain example: ["example.com"]
#    Multiple domains example: ["example.com", "example.org"]
#
#    In templates, domains are available as:
#      ${SECRET_DOMAIN}   - Primary domain (first in list)
#      ${SECRET_DOMAIN_2} - Second domain
#      ${SECRET_DOMAIN_3} - Third domain, etc.
cloudflare_domains: []

# -- Cloudflare API Token with required permissions.
#    (REQUIRED) - See README "Stage 3: Cloudflare configuration" for creation steps.
#    Required permissions:
#      - Zone:DNS:Edit (from template)
#      - Account:Cloudflare Tunnel:Read (add manually)
#    TIP: Create token at: Cloudflare Portal → Manage Account → Account API Tokens
cloudflare_token: ""
# ==============================================================================
# CILIUM NETWORKING (Advanced)
# ==============================================================================

# -- Load balancer mode for Cilium.
#    DSR (Direct Server Return) is more efficient but requires compatible network.
#    SNAT works in all environments but adds latency.
#    (OPTIONAL) / (DEFAULT: "dsr")
#    Values: "dsr" or "snat"
#    REF: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/
# cilium_loadbalancer_mode: ""

# -- Use Cilium prerelease version (1.19.x) instead of stable (1.18.x).
#    (OPTIONAL) / (DEFAULT: false)
#    Enables testing of new Cilium features before general availability.
#    WARNING: Pre-release versions are not recommended for production.
#    REF: https://github.com/cilium/cilium/releases
# cilium_use_prerelease: false

# -- Cilium prerelease version to use when cilium_use_prerelease is true.
#    (OPTIONAL) / (DEFAULT: 1.19.0-pre.3)
#    Check https://github.com/cilium/cilium/releases for available pre-releases.
# cilium_prerelease_version: "1.19.0-pre.3"

# -- BGP Configuration (for advanced networking setups)
#    Enable BGP peering with your router for dynamic route advertisement.
#    All three BGP settings must be configured together to enable BGP.
#    (OPTIONAL) - Only needed if your router supports BGP
#    REF: https://docs.cilium.io/en/latest/network/bgp-control-plane/

# -- BGP router IP address (your router's IP that speaks BGP)
#    Example: "192.168.1.1"
# cilium_bgp_router_addr: ""

# -- BGP ASN for your router
#    Example: "64512"
# cilium_bgp_router_asn: ""

# -- BGP ASN for Kubernetes nodes
#    Example: "64513"
# cilium_bgp_node_asn: ""

# ==============================================================================
# CONTROL PLANE SCHEDULING
# ==============================================================================

# -- Allow scheduling workloads on control plane nodes.
#    When true, removes the node-role.kubernetes.io/control-plane:NoSchedule taint
#    from control plane nodes, allowing regular workloads to run there.
#    When false, only system components with tolerations can run on control planes.
#    (OPTIONAL) / (DEFAULT: false)
#    TIP: Set to true if you have limited nodes and want to maximize resources.
#    TIP: Set to false for production clusters with dedicated worker nodes.
# allow_scheduling_on_control_planes: false

# ==============================================================================
# PROXMOX INTEGRATION (Optional)
# ==============================================================================
# Configuration for Proxmox CSI Plugin (and optionally CCM).
# Required if deploying persistent storage via Proxmox CSI.
# REF: docs/proxmox-csi-implementation.md

# -- Proxmox API URL for CSI (and CCM if using Approach B) communication.
#    (REQUIRED for Proxmox integration)
#    Example: "https://192.168.1.10:8006/api2/json"
# proxmox_api_url: ""

# -- Skip TLS certificate verification for self-signed Proxmox certs.
#    (OPTIONAL) / (DEFAULT: false)
# proxmox_insecure: false

# -- Proxmox region name (identifies the Proxmox cluster).
#    Used for topology.kubernetes.io/region label.
#    (OPTIONAL) / (DEFAULT: "talos-k8s")
# proxmox_region: ""

# -- Proxmox storage pool name for CSI volumes.
#    Must support disk images (e.g., local-lvm, local-zfs, ceph).
#    (OPTIONAL) / (DEFAULT: "local-lvm")
# proxmox_storage: ""

# -- Proxmox CSI API Token ID (from step 1.4 of implementation guide)
#    (REQUIRED for CSI) Format: "user@realm!token-name"
#    Example: "kubernetes-csi@pve!csi"
# proxmox_csi_token_id: ""

# -- Proxmox CSI API Token Secret
#    (REQUIRED for CSI) - The secret value from token creation
# proxmox_csi_token_secret: ""

# -- Proxmox CCM API Token ID (from step 1.3 of implementation guide)
#    (REQUIRED for Approach B only) Format: "user@realm!token-name"
#    Example: "kubernetes-ccm@pve!ccm"
#    NOTE: Skip if using Approach A (Static Labels)
# proxmox_ccm_token_id: ""

# -- Proxmox CCM API Token Secret
#    (REQUIRED for Approach B only) - The secret value from token creation
#    NOTE: Skip if using Approach A (Static Labels)
# proxmox_ccm_token_secret: ""

# ==============================================================================
# KGATEWAY CONFIGURATION (Optional - Envoy Control Plane)
# ==============================================================================
# kgateway is the next-generation Gateway API control plane
# REF: https://kgateway.dev/
# REF: docs/ai-context/agentgateway-mcp.md

# -- Enable kgateway deployment.
#    (OPTIONAL) / (DEFAULT: true)
#    When enabled, deploys kgateway as the Gateway API control plane.
# kgateway_enabled: true

# -- Gateway API CRDs version (kubernetes-sigs experimental channel).
#    (OPTIONAL) / (DEFAULT: "v1.4.1")
#    Required for kgateway experimental features.
# gateway_api_version: "v1.4.1"

# -- kgateway Helm chart version.
#    (OPTIONAL) / (DEFAULT: "v2.2.0-beta.4")
# kgateway_version: "v2.2.0-beta.4"

# -- agentgateway Helm chart version.
#    (OPTIONAL) / (DEFAULT: "v2.2.0-beta.4")
#    Used when agentgateway_enabled is true.
# agentgateway_version: "v2.2.0-beta.4"

# ==============================================================================
# MCP GATEWAY (Optional - Model Context Protocol)
# ==============================================================================
# MCP Gateway enables hosting MCP servers with SSE/WebSocket transport.
# Creates a dedicated Gateway at mcp.<domain> for MCP server routing.
# REF: https://modelcontextprotocol.io/specification/2025-11-25/basic/authorization

# -- Enable MCP Gateway functionality.
#    (OPTIONAL) / (DEFAULT: false)
# mcp_gateway_enabled: true

# -- MCP session timeout in seconds.
#    Controls connection idle and max duration timeouts for long-running MCP operations.
#    (OPTIONAL) / (DEFAULT: 3600 - 1 hour)
# mcp_session_timeout: 3600

# ==============================================================================
# AZURE OPENAI - US EAST REGION
# ==============================================================================
# Models: gpt-4.1, gpt-4.1-nano, gpt-4o-mini, o3, o4-mini
#         text-embedding-3-small, text-embedding-ada-002

# -- Azure OpenAI US East API Key for authentication.
#    (optional) - From Azure Portal
# azure_openai_us_east_api_key: ""

# -- Azure OpenAI US East resource name (the subdomain of your endpoint).
#    (optional)
#    Example: "my-openai" for https://my-openai.openai.azure.com
# azure_openai_us_east_resource_name: ""

# ==============================================================================
# AZURE OPENAI - US EAST2 REGION
# ==============================================================================
# Models: gpt-5, gpt-5-chat, gpt-5-mini, gpt-5-nano, gpt-5.1, gpt-5.1-chat
#         gpt-5.1-codex, gpt-5.1-codex-mini, gpt-audio, gpt-audio-mini
#         text-embedding-3-large

# -- Azure OpenAI US East2 API Key for authentication.
#    (optional) - From Azure Portal
# azure_openai_us_east2_api_key: ""

# -- Azure OpenAI US East2 resource name (the subdomain of your endpoint).
#    (optional)
#    Example: "my-openai" for https://my-openai-east2.openai.azure.com
# azure_openai_us_east2_resource_name: ""

# ==============================================================================
# AZURE COHERE RERANK API (Reranking Models)
# ==============================================================================
# Models: cohere-rerank-v3-5 (via passthrough endpoint /v2/rerank)

# -- Azure Cohere Rerank API Key for authentication.
#    (optional) - From Azure AI Studio
# azure_cohere_rerank_api_key: ""

# -- Azure Cohere Rerank API base URL.
#    (optional) - Full URL to the Azure AI inference endpoint
#    Example: "https://my-cohere-rerank.eastus.models.ai.azure.com/v2/rerank"
# azure_cohere_rerank_api_base: ""

# ==============================================================================
# AZURE COHERE EMBED API (Embedding Models)
# ==============================================================================
# Models: cohere-embed-v3 (via passthrough endpoint /v2/embed)

# -- Azure Cohere Embed API Key for authentication.
#    (optional) - From Azure AI Studio
# azure_cohere_embed_api_key: ""

# -- Azure Cohere Embed API base URL.
#    (optional) - Full URL to the Azure AI inference endpoint
#    Example: "https://my-cohere-embed.ai.azure.com/models"
# azure_cohere_embed_api_base: ""

# ==============================================================================
# AZURE ANTHROPIC API (Claude Models via Azure AI)
# ==============================================================================
# Models: claude-opus-4-5, claude-sonnet-4-5, claude-opus-4-1, claude-haiku-4-5

# -- Azure Anthropic API Key for authentication.
#    (optional) - From Azure AI Studio
# azure_anthropic_api_key: ""

# -- Azure Anthropic API base URL for Claude models via Azure AI.
#    (optional) - Full URL to the Azure AI inference endpoint
#    Example: "https://claude-sonnet-4-5.services.ai.azure.com"
# azure_anthropic_api_base: ""

# ==============================================================================
# AZURE ENTRA ID AUTHENTICATION
# ==============================================================================
# -- Azure Entra ID Authentication (optional - alternative to API key)
#    Use these for production workloads instead of API key.
# azure_tenant_id: ""
# azure_client_id: ""
# azure_client_secret: ""

# ==============================================================================
# OBSERVABILITY STACK (VictoriaMetrics-based)
# ==============================================================================
# Kubernetes infrastructure metrics with VictoriaMetrics and Grafana dashboards.
# NOTE: Legacy kube-prometheus-stack has been moved to archive/.

# -- Enable metrics scraping features (ServiceMonitors, PodMonitors, NetworkPolicy).
#    (OPTIONAL) / (DEFAULT: victoria_metrics_enabled)
#    This is auto-derived from victoria_metrics_enabled. Only set explicitly if you
#    need to override (e.g., disable scraping while keeping metrics storage).
# observability_enabled: true

# -- Grafana admin password.
#    (OPTIONAL) / (DEFAULT: "admin")
#    WARNING: Change this for production deployments!
# grafana_admin_password: ""

# -- Storage size for Grafana PVC.
#    (OPTIONAL) / (DEFAULT: "10Gi")
# grafana_storage_size: "10Gi"

# -- Enable Proxmox VE dashboards in Grafana.
#    (OPTIONAL) / (DEFAULT: proxmox_csi_enabled)
#    Requires Proxmox to push metrics to VictoriaMetrics via InfluxDB protocol.
#    Configure Proxmox: Datacenter > Metric Server > Add InfluxDB
#    Dashboards: Host/VM metrics (16060), VictoriaMetrics-native (13307)
# proxmox_dashboards_enabled: true

# ==============================================================================
# UNIFI MONITORING (Optional - UnPoller metrics collection)
# ==============================================================================
# UnPoller collects metrics from UniFi Controller and exports to Prometheus.
# Provides Grafana dashboards for switches, access points, gateways, and clients.
# REF: https://unpoller.com/

# -- Enable UniFi monitoring via UnPoller.
#    (OPTIONAL) / (DEFAULT: false)
#    Deploys UnPoller to collect metrics from UniFi Controller.
#    Dashboards: USW (11312), USG/UDM (11313), UAP (11314), Clients (11315)
# unifi_enabled: true

# -- UniFi Controller URL.
#    (REQUIRED when unifi_enabled=true)
#    For UniFi OS devices (UDM/UDM-Pro/UXG): use port 443 or omit port
#    For legacy CloudKey/self-hosted: use port 8443
# unifi_url: "https://192.168.1.1"

# -- UniFi Controller username.
#    (REQUIRED when unifi_enabled=true)
#    Create a read-only local user in UniFi Controller for polling.
# unifi_user: "unpoller"

# -- UniFi Controller password.
#    (REQUIRED when unifi_enabled=true)
#    WARNING: Use a strong password and consider SOPS encryption.
# unifi_pass: "changeme"

# -- Skip SSL certificate verification.
#    (OPTIONAL) / (DEFAULT: false)
#    Set to true for self-signed certificates.
# unifi_verify_ssl: false

# ==============================================================================
# VICTORIAMETRICS STACK
# ==============================================================================
# VictoriaMetrics provides a resource-efficient metrics stack.
# Deploys VMSingle, VMAgent, VMAlert, and Grafana (vm-grafana).
# REF: https://docs.victoriametrics.com/

# -- Enable VictoriaMetrics stack deployment.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, also auto-enables observability_enabled for ServiceMonitors/PodMonitors.
# victoria_metrics_enabled: false

# -- VMSingle storage size for metrics data.
#    (OPTIONAL) / (DEFAULT: "50Gi")
# vm_storage_size: "50Gi"

# -- Metrics retention period in days.
#    (OPTIONAL) / (DEFAULT: 14)
# vm_retention_days: 14

# -- Storage class for VictoriaMetrics PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# vm_storage_class: "proxmox-csi"

# -- VMSingle resource requests.
#    (OPTIONAL) / (DEFAULTs shown)
# vm_cpu_request: "200m"
# vm_memory_request: "512Mi"

# -- VMSingle resource limits.
#    (OPTIONAL) / (DEFAULTs shown)
# vm_cpu_limit: "1000m"
# vm_memory_limit: "2Gi"

# ==============================================================================
# VICTORIALOGS (Optional - Log aggregation with VictoriaMetrics)
# ==============================================================================
# VictoriaLogs provides efficient log storage and querying.
# Requires Vector for log collection from nodes.
# REF: https://docs.victoriametrics.com/victorialogs/

# -- Enable VictoriaLogs deployment.
#    (OPTIONAL) / (DEFAULT: false)
#    NOTE: When enabled, Vector is automatically enabled for log collection.
# victoria_logs_enabled: false

# -- VictoriaLogs storage size.
#    (OPTIONAL) / (DEFAULT: "20Gi")
# vl_storage_size: "20Gi"

# -- Log retention period in days.
#    (OPTIONAL) / (DEFAULT: 14)
# vl_retention_days: 14

# -- Storage class for VictoriaLogs PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# vl_storage_class: "proxmox-csi"

# -- VictoriaLogs resource requests.
#    (OPTIONAL) / (DEFAULTs shown)
# vl_cpu_request: "100m"
# vl_memory_request: "256Mi"

# -- VictoriaLogs resource limits.
#    (OPTIONAL) / (DEFAULTs shown)
# vl_cpu_limit: "500m"
# vl_memory_limit: "1Gi"

# ==============================================================================
# VECTOR LOG AGENT (Optional - Log collection for VictoriaLogs)
# ==============================================================================
# Vector runs as a DaemonSet to collect logs from all nodes.
# Automatically enabled when victoria_logs_enabled is true.
# REF: https://vector.dev/docs/

# -- Enable Vector DaemonSet.
#    (OPTIONAL) / (DEFAULT: victoria_logs_enabled)
#    Set explicitly to override the default behavior.
# vector_enabled: false

# -- Vector resource requests per node.
#    (OPTIONAL) / (DEFAULTs shown)
# vector_cpu_request: "50m"
# vector_memory_request: "128Mi"

# -- Vector resource limits per node.
#    (OPTIONAL) / (DEFAULTs shown)
# vector_cpu_limit: "200m"
# vector_memory_limit: "512Mi"

# ==============================================================================
# ENHANCED LOG COLLECTION (Optional - Additional log sources)
# ==============================================================================
# Additional log sources for comprehensive observability.
# All features automatically enabled when victoria_logs_enabled is true.

# -- Enable OpenTelemetry Operator.
#    (OPTIONAL) / (DEFAULT: victoria_logs_enabled)
#    Deploys the OTEL Operator which manages OpenTelemetryCollector CRDs.
#    Required for K8s events collection via k8seventsreceiver.
#    REF: https://opentelemetry.io/docs/kubernetes/operator/
# opentelemetry_operator_enabled: false

# -- Enable OpenTelemetry K8s Events Collector.
#    (OPTIONAL) / (DEFAULT: victoria_logs_enabled)
#    Captures ephemeral K8s events (normally expire after ~1 hour) and forwards
#    them to VictoriaLogs via OTLP HTTP for persistent storage and debugging.
#    NOTE: Replaces abandoned kubernetes-event-exporter (Part 11 of monitoring guide).
#    REF: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/k8seventsreceiver
# opentelemetry_k8s_events_enabled: false

# -- Enable Talos system log collection.
#    (OPTIONAL) / (DEFAULT: victoria_logs_enabled)
#    Collects Talos kernel and service logs via Vector UDP sockets.
#    Requires extraKernelArgs in Talos schematic for kernel logs (port 6050).
#    Service logs forwarded via machine.logging.destinations (port 6051).
#    REF: https://www.talos.dev/v1.9/talos-guides/configuration/logging/
# talos_system_logs_enabled: false

# -- Enable API server audit log collection.
#    (OPTIONAL) / (DEFAULT: true)
#    Collects Kubernetes API server audit logs from /var/log/audit/kube/*.log.
#    Provides visibility into API server requests for security and debugging.
# api_server_audit_logs_enabled: true

# ==============================================================================
# TEMPO TRACING (Optional - Distributed tracing backend)
# ==============================================================================
# Grafana Tempo provides distributed tracing with Grafana integration.
# Receives traces via OTLP and stores them for querying.
# REF: https://grafana.com/docs/tempo/latest/

# -- Enable Tempo deployment.
#    (OPTIONAL) / (DEFAULT: false)
# tempo_enabled: false

# -- Tempo storage size for trace data.
#    (OPTIONAL) / (DEFAULT: "10Gi")
# tempo_storage_size: "10Gi"

# -- Trace retention period in days.
#    (OPTIONAL) / (DEFAULT: 7)
# tempo_retention_days: 7

# -- Storage class for Tempo PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# tempo_storage_class: "proxmox-csi"

# -- S3 bucket for trace storage (if using MinIO).
#    (OPTIONAL) / (DEFAULT: "tempo-traces")
#    NOTE: Only used if minio_enabled is true.
# tempo_s3_bucket: "tempo-traces"

# -- Tempo resource requests.
#    (OPTIONAL) / (DEFAULTs shown)
# tempo_cpu_request: "100m"
# tempo_memory_request: "256Mi"

# -- Tempo resource limits.
#    (OPTIONAL) / (DEFAULTs shown)
# tempo_cpu_limit: "500m"
# tempo_memory_limit: "1Gi"

# ==============================================================================
# ONEDEV CONFIGURATION (Optional - Git Server with CI/CD)
# ==============================================================================
# OneDev is an All-In-One DevOps Platform with Git hosting, CI/CD, and packages.
# REF: https://docs.onedev.io/installation-guide/deploy-to-k8s
# REF: docs/onedev-implementation.md

# -- Enable OneDev deployment.
#    (OPTIONAL) / (DEFAULT: false)
# onedev_enabled: true

# -- OneDev admin password (initial setup).
#    (REQUIRED if onedev_enabled) - Will be encrypted with SOPS
#    NOTE: Change this after initial setup via the web UI
# onedev_admin_password: "your-secure-password"

# -- Storage size for OneDev data PVC.
#    (OPTIONAL) / (DEFAULT: "100Gi")
#    NOTE: Size depends on repository data - minimum 3x your total repo size
# onedev_storage_size: "100Gi"

# -- Storage class for OneDev PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# onedev_storage_class: "proxmox-csi"

# ==============================================================================
# ONEDEV EXTERNAL DATABASE (Optional)
# ==============================================================================
# If not set, uses embedded H2 database (suitable for small deployments).
# For production with many users/projects, use external MySQL/PostgreSQL.

# -- External database type.
#    (OPTIONAL) / (DEFAULT: embedded H2)
#    Options: "mysql", "postgresql", "mariadb", "mssql"
# onedev_database_type: "mysql"

# -- External database host.
#    (REQUIRED if onedev_database_type is set)
#    Example: "mysql.database.svc" or "192.168.1.50"
# onedev_database_host: ""

# -- External database port.
#    (OPTIONAL) / (DEFAULT: "3306")
# onedev_database_port: "3306"

# -- External database name.
#    (OPTIONAL) / (DEFAULT: "onedev")
# onedev_database_name: "onedev"

# -- External database user.
#    (OPTIONAL) / (DEFAULT: "onedev")
# onedev_database_user: "onedev"

# -- External database password.
#    (REQUIRED if onedev_database_type is set)
# onedev_database_password: ""

# ==============================================================================
# ONEDEV ADVANCED CONFIGURATION
# ==============================================================================

# -- SSH service port for git operations.
#    (OPTIONAL) / (DEFAULT: 6611)
#    NOTE: If you need SSH access, configure split-DNS or expose via LoadBalancer
# onedev_ssh_port: 6611

# -- Resource limits for OneDev container.
#    (OPTIONAL) / Defaults below are suitable for small-medium deployments
# onedev_cpu_limit: "2000m"
# onedev_memory_limit: "4Gi"
# onedev_cpu_request: "500m"
# onedev_memory_request: "2Gi"

# ==============================================================================
# WORKOS AUTHKIT (Optional - OAuth 2.1 / MCP Authentication)
# ==============================================================================
# WorkOS AuthKit provides MCP 2025-11-25 compliant authorization.
# Supports CIMD, RFC 8707, Cross App Access, and enterprise SSO.
# REF: https://workos.com/docs/authkit/mcp

# -- WorkOS Client ID (from WorkOS Dashboard).
#    (REQUIRED for WorkOS integration)
# workos_client_id: "client_xxx"

# -- WorkOS Client Secret (from WorkOS Dashboard).
#    (REQUIRED for WorkOS integration) - Will be encrypted with SOPS
# workos_client_secret: "sk_live_xxx"

# -- WorkOS AuthKit subdomain (your-subdomain.authkit.app).
#    (REQUIRED for WorkOS integration)
#    Example: "mycompany" for mycompany.authkit.app
# workos_subdomain: ""

# ==============================================================================
# KEYCLOAK CONFIGURATION (Optional - OIDC Authentication Provider)
# ==============================================================================
# Keycloak provides enterprise-grade identity and access management.
# Integrates with kgateway via SecurityPolicy for OIDC authentication.

# -- Enable Keycloak deployment.
#    (OPTIONAL) / (DEFAULT: false)
# keycloak_enabled: true

# -- Keycloak admin password.
#    (REQUIRED if keycloak_enabled) - Will be encrypted with SOPS
# keycloak_admin_password: "your-secure-password"

# -- PostgreSQL database password for Keycloak.
#    (REQUIRED if keycloak_enabled) - Will be encrypted with SOPS
# keycloak_db_password: "your-db-password"

# -- Number of Keycloak replicas for HA.
#    (OPTIONAL) / (DEFAULT: 2)
# keycloak_replicas: 2

# -- OIDC client secret for kgateway integration.
#    (REQUIRED if keycloak_enabled) - Will be created in Keycloak after deployment
#    NOTE: Generate this value after configuring Keycloak realm and client.
#    Leave as placeholder until Keycloak is running and client is configured.
# keycloak_oidc_client_secret: "REPLACE_AFTER_KEYCLOAK_SETUP"

# -- Cookie domain for SSO across subdomains.
#    (OPTIONAL) - Set to "yourdomain.com" for cross-subdomain SSO
#    NOTE: Do NOT include leading dot - modern browsers treat both identically
#    Example: "example.com" to share sessions across *.example.com
# keycloak_oidc_cookie_domain: "example.com"

# ==============================================================================
# KGATEWAY OAUTH2 CONFIGURATION
# ==============================================================================
# Enables OAuth2 authentication via Keycloak for internal Gateway.
# When enabled, all routes through the internal Gateway will require OIDC login.
# Requires: keycloak_enabled and keycloak_oidc_client_secret

# -- Enable OAuth2 for internal Gateway.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, users accessing internal services (Hubble UI, etc.) will be
#    redirected to Keycloak for authentication.
# kgateway_oauth2_enabled: false

# ==============================================================================
# KEYCLOAK POSTGRESQL CONFIGURATION
# ==============================================================================

# -- Enable built-in CloudNativePG PostgreSQL for Keycloak.
#    (OPTIONAL) / (DEFAULT: true)
#    Set to false if using external PostgreSQL.
# keycloak_postgresql_enabled: true

# -- Number of PostgreSQL replicas.
#    (OPTIONAL) / (DEFAULT: 3)
#    NOTE: Use odd numbers for quorum (1, 3, 5)
# keycloak_postgresql_replicas: 3

# -- PostgreSQL storage size.
#    (OPTIONAL) / (DEFAULT: "10Gi")
# keycloak_postgresql_storage_size: "10Gi"

# ==============================================================================
# KEYCLOAK RESOURCE LIMITS
# ==============================================================================

# -- Keycloak resource requests.
#    (OPTIONAL) / (DEFAULTs shown)
# keycloak_cpu_request: "250m"
# keycloak_memory_request: "512Mi"

# -- Keycloak resource limits.
#    (OPTIONAL) / (DEFAULTs shown)
# keycloak_cpu_limit: "1000m"
# keycloak_memory_limit: "1Gi"

# ==============================================================================
# KEYCLOAK ENTRA ID IDENTITY PROVIDER (Optional - Federation with Microsoft)
# ==============================================================================
# Configure Microsoft Entra ID as an external identity provider in Keycloak.
# Users will be able to "Sign in with Microsoft" using their organizational accounts.
# REF: https://blog.ght1pc9kc.fr/en/2023/configure-azure-entra-id-as-idp-on-keycloak/

# -- Enable Microsoft Entra ID as an identity provider.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, users will see a "Microsoft Entra ID" button on the Keycloak login page.
# keycloak_entra_id_enabled: true

# -- Azure Entra ID Tenant ID (Directory ID).
#    (REQUIRED if keycloak_entra_id_enabled) - From Azure Portal → Entra ID → Overview
#    Format: GUID (e.g., "12345678-1234-1234-1234-123456789abc")
# keycloak_entra_id_tenant_id: ""

# -- Azure App Registration Client ID (Application ID).
#    (REQUIRED if keycloak_entra_id_enabled) - From Azure Portal → App Registrations
#    NOTE: Create a new app registration:
#      1. Go to Azure Portal → Microsoft Entra ID → App Registrations → New Registration
#      2. Name: "Keycloak" (or your preferred name)
#      3. Supported account types: "Accounts in this organizational directory only"
#      4. Redirect URI: https://auth.<your-domain>/realms/k8s-cluster/broker/entra-id/endpoint
#    Format: GUID (e.g., "12345678-1234-1234-1234-123456789abc")
# keycloak_entra_id_client_id: ""

# -- Azure App Registration Client Secret.
#    (REQUIRED if keycloak_entra_id_enabled) - Will be encrypted with SOPS
#    NOTE: Create client secret:
#      1. In your app registration → Certificates & secrets → New client secret
#      2. Copy the Value (NOT the Secret ID) immediately - it's only shown once!
# keycloak_entra_id_client_secret: ""

# ------------------------------------------------------------------------------
# Keycloak Google Identity Provider (Optional - federate with Google)
# ------------------------------------------------------------------------------
# Enables Google Workspace/Gmail accounts to authenticate via Keycloak.
# Required for applications that need Google group-based RBAC.
# REF: https://www.keycloak.org/docs/latest/server_admin/#google
# REF: https://console.cloud.google.com/apis/credentials

# -- Enable Google as Keycloak identity provider.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, adds Google login option to Keycloak authentication
# keycloak_google_enabled: false

# -- Google OAuth Client ID.
#    (REQUIRED if keycloak_google_enabled)
#    NOTE: Create in Google Cloud Console:
#      1. APIs & Services → Credentials → Create OAuth 2.0 Client ID
#      2. Application type: Web application
#      3. Authorized redirect URI: https://keycloak.${domain}/realms/${realm}/broker/google/endpoint
# keycloak_google_client_id: ""

# -- Google OAuth Client Secret.
#    (REQUIRED if keycloak_google_enabled) - Will be encrypted with SOPS
#    NOTE: Copy the client secret from Google Cloud Console immediately after creation
# keycloak_google_client_secret: ""

# ==============================================================================
# GITHUB IDENTITY PROVIDER (Optional - Keycloak Identity Brokering)
# ==============================================================================
# Enable GitHub OAuth for Keycloak authentication.
# Required for applications that need GitHub-based authentication.
# REF: https://www.keycloak.org/docs/latest/server_admin/#github
# REF: https://github.com/settings/developers

# -- Enable GitHub as Keycloak identity provider.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, adds GitHub login option to Keycloak authentication
# keycloak_github_enabled: false

# -- GitHub OAuth App Client ID.
#    (REQUIRED if keycloak_github_enabled)
#    NOTE: Create in GitHub Settings:
#      1. Settings → Developer settings → OAuth Apps → New OAuth App
#      2. Homepage URL: https://auth.${domain}
#      3. Authorization callback URL: https://auth.${domain}/realms/k8s-cluster/broker/github/endpoint
# keycloak_github_client_id: ""

# -- GitHub OAuth App Client Secret.
#    (REQUIRED if keycloak_github_enabled) - Will be encrypted with SOPS
#    NOTE: Generate client secret in GitHub OAuth App settings
# keycloak_github_client_secret: ""

# ==============================================================================
# AGENTGATEWAY CONFIGURATION (Optional - MCP 2025-11-25 OAuth Proxy)
# ==============================================================================
# agentgateway wraps Keycloak to provide MCP spec-compliant OAuth.
# Required for MCP clients that need DCR/CIMD support.
# REF: https://agentgateway.dev/docs/mcp/mcp-authn/

# -- Enable agentgateway for MCP authentication.
#    (OPTIONAL) / (DEFAULT: false)
# agentgateway_enabled: true

# -- Load balancer IP for agentgateway.
#    (REQUIRED if agentgateway_enabled) - Must be an UNUSED IP within node_cidr
#    Example: "192.168.1.147"
# agentgateway_addr: ""

# -- agentgateway MCP scopes.
#    (OPTIONAL) / (DEFAULT: ["openid", "profile", "email", "offline_access"])
# agentgateway_scopes:
#   - openid
#   - profile
#   - email
#   - offline_access

# -- Keycloak client secret for agentgateway.
#    (OPTIONAL) - Defaults to keycloak_oidc_client_secret if not set
#    Will be encrypted with SOPS
#    NOTE: Use a separate client secret if agentgateway needs different
#    permissions than the main OIDC client.
#    Generate with: openssl rand -base64 32 | tr -d '/+=' | head -c 32
# keycloak_agentgateway_client_secret: ""

# ==============================================================================
# OBOT CONFIGURATION (Optional - Multi-Tenant MCP Gateway)
# ==============================================================================
# obot is a self-hosted AI agent platform that provides a multi-tenant MCP gateway.
# It integrates directly with Microsoft Entra ID for authentication.
# REF: https://github.com/jrmatherly/obot-entraid
# REF: docs/obot-entraid-implementation-guide.md

# -- Enable obot MCP gateway deployment.
#    (OPTIONAL) / (DEFAULT: false)
# obot_enabled: true

# -- Obot hostname (subdomain).
#    (OPTIONAL) / (DEFAULT: "obot")
#    Results in obot.<primary_domain>
# obot_hostname: "obot"

# ==============================================================================
# OBOT POSTGRESQL CONFIGURATION
# ==============================================================================

# -- PostgreSQL host for obot.
#    (OPTIONAL) - Leave empty to use CloudNativePG (recommended)
# obot_postgres_host: ""

# -- PostgreSQL database name.
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_postgres_db: "obot"

# -- PostgreSQL username.
#    (OPTIONAL) / (DEFAULT: "obot")
# obot_postgres_user: "obot"

# -- PostgreSQL password for obot database.
#    (REQUIRED if obot_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 24
# obot_postgres_password: ""

# ==============================================================================
# OBOT CLOUDNATIVEPG CONFIGURATION
# ==============================================================================

# -- Number of PostgreSQL replicas (CloudNativePG cluster).
#    (OPTIONAL) / (DEFAULT: 3)
#    NOTE: Uses CloudNativePG for high-availability PostgreSQL
# obot_postgresql_replicas: 3

# -- PostgreSQL storage size per replica.
#    (OPTIONAL) / (DEFAULT: "10Gi")
# obot_postgresql_storage_size: "10Gi"

# ==============================================================================
# OBOT MCP SERVER CONFIGURATION
# ==============================================================================

# -- Namespace for dynamically created MCP servers.
#    (OPTIONAL) / (DEFAULT: "obot-mcp")
# obot_mcp_namespace: "obot-mcp"

# ==============================================================================
# OBOT SECRETS
# ==============================================================================

# -- Session cookie secret (32 bytes base64).
#    (REQUIRED if obot_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 32
# obot_cookie_secret: ""

# -- Custom encryption key for data at rest (32 bytes base64).
#    (OPTIONAL) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 32
# obot_encryption_key: ""

# -- Initial admin bootstrap token.
#    (OPTIONAL) - For initial setup without SSO
#    Generate with: openssl rand -hex 16
# obot_bootstrap_token: ""

# ==============================================================================
# OBOT ENTRA ID AUTHENTICATION
# ==============================================================================
# Configure Microsoft Entra ID for native obot authentication.
# NOTE: This creates a separate Azure App Registration from Keycloak's.

# -- Azure Entra ID Tenant ID for obot.
#    (REQUIRED if obot_enabled)
#    Format: GUID (e.g., "12345678-1234-1234-1234-123456789abc")
# obot_entra_tenant_id: ""

# -- Azure App Registration Client ID for obot.
#    (REQUIRED if obot_enabled)
#    NOTE: Create app registration with:
#      - Redirect URI: https://obot.<domain>/oauth2/callback
#      - API Permissions: Microsoft Graph → User.Read, email, openid, profile
# obot_entra_client_id: ""

# -- Azure App Registration Client Secret for obot.
#    (REQUIRED if obot_enabled) - Will be encrypted with SOPS
# obot_entra_client_secret: ""

# ==============================================================================
# OBOT USER MANAGEMENT
# ==============================================================================

# -- Comma-separated list of admin email addresses.
#    (OPTIONAL) - Users with full administrative access
#    Example: "admin@example.com,devops@example.com"
# obot_admin_emails: ""

# -- Comma-separated list of owner email addresses.
#    (OPTIONAL) - Users with owner-level access (above admin)
#    Example: "cto@example.com"
# obot_owner_emails: ""

# ==============================================================================
# OBOT STORAGE CONFIGURATION
# ==============================================================================

# -- Storage size for obot data PVC.
#    (OPTIONAL) / (DEFAULT: "20Gi")
# obot_storage_size: "20Gi"

# -- Storage class for obot PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# obot_storage_class: "proxmox-csi"

# ==============================================================================
# OBOT RESOURCE LIMITS
# ==============================================================================

# -- Number of obot replicas.
#    (OPTIONAL) / (DEFAULT: 1)
#    NOTE: Limited to 1 when using directory storage (RWO PVC).
#          Set obot_workspace_provider="s3" to enable multiple replicas.
# obot_replicas: 1

# -- obot Docker image and Helm chart version (without 'v' prefix).
#    The template automatically adds 'v' prefix for Docker image tags.
#    (OPTIONAL) / (DEFAULT: "0.2.20")
# obot_version: "0.2.20"

# -- CPU request for obot container.
#    (OPTIONAL) / (DEFAULT: "500m")
# obot_cpu_request: "500m"

# -- CPU limit for obot container.
#    (OPTIONAL) / (DEFAULT: "2000m")
# obot_cpu_limit: "2000m"

# -- Memory request for obot container.
#    (OPTIONAL) / (DEFAULT: "1Gi")
# obot_memory_request: "1Gi"

# -- Memory limit for obot container.
#    (OPTIONAL) / (DEFAULT: "4Gi")
# obot_memory_limit: "4Gi"

# ==============================================================================
# OBOT ADVANCED CONFIGURATION
# ==============================================================================

# -- Encryption provider for data at rest.
#    (OPTIONAL) / (DEFAULT: "custom")
#    Options: "custom", "azure-keyvault", "aws-kms", "gcp-kms"
# obot_encryption_provider: "custom"

# -- Use agentgateway for LLM requests with advanced features.
#    (OPTIONAL) / (DEFAULT: false)
#    When enabled, routes LLM traffic through agentgateway for rate limiting,
#    prompt guards, FinOps metrics, and MCP-focused features.
#    Requires: agentgateway_enabled=true and Azure OpenAI backends configured.
# obot_use_agentgateway: false

# ==============================================================================
# OBOT S3/MINIO WORKSPACE STORAGE (Optional - Enables Multi-Replica Scaling)
# ==============================================================================
# Configure S3-compatible storage (MinIO, AWS S3, etc.) for obot workspaces.
# This enables horizontal scaling with multiple replicas by removing the
# dependency on RWO (ReadWriteOnce) PVC storage.
# REF: https://docs.obot.ai/configuration/workspace-provider/

# -- Workspace storage provider type.
#    (OPTIONAL) / (DEFAULT: "directory")
#    Options: "directory" (local PVC), "s3" (S3-compatible), "azure" (Azure Blob)
#    NOTE: Use "s3" with MinIO to enable multiple obot replicas
# obot_workspace_provider: "s3"

# -- S3 bucket name for workspace storage.
#    (REQUIRED if obot_workspace_provider=s3)
#    Create this bucket in MinIO before enabling
# obot_s3_bucket: "obot-workspaces"

# -- S3-compatible endpoint URL.
#    (REQUIRED if obot_workspace_provider=s3 and not using AWS S3)
#    Example for MinIO: "http://minio.minio.svc.cluster.local:9000"
# obot_s3_endpoint: "http://minio.minio.svc.cluster.local:9000"

# -- S3 region.
#    (OPTIONAL) / (DEFAULT: "us-east-1")
#    For MinIO, this can be any value (e.g., "us-east-1")
# obot_s3_region: "us-east-1"

# -- S3 access key (MinIO access key).
#    (REQUIRED if obot_workspace_provider=s3) - Will be encrypted with SOPS
# obot_s3_access_key: ""

# -- S3 secret key (MinIO secret key).
#    (REQUIRED if obot_workspace_provider=s3) - Will be encrypted with SOPS
# obot_s3_secret_key: ""

# -- Use path-style S3 URLs instead of virtual-hosted style.
#    (OPTIONAL) / (DEFAULT: false)
#    Set to true for MinIO endpoints without wildcard DNS (e.g., s3.domain.com)
#    Path-style: https://s3.domain.com/bucket/
#    Virtual-hosted: https://bucket.s3.domain.com/ (requires *.s3.domain.com DNS)
# obot_s3_use_path_style: true

# ==============================================================================
# MINIO CONFIGURATION (Optional - S3-compatible Object Storage)
# ==============================================================================
# MinIO provides S3-compatible object storage for services like obot.
# Deployed in the shared "storage" namespace for use by multiple applications.
# REF: https://min.io/docs/minio/kubernetes/upstream/
# REF: https://github.com/minio/minio/tree/master/helm/minio

# -- Enable MinIO deployment.
#    (OPTIONAL) / (DEFAULT: false)
# minio_enabled: true

# -- MinIO Helm chart version.
#    (OPTIONAL) / (DEFAULT: "5.4.0")
# minio_chart_version: "5.4.0"

# -- Deployment mode for MinIO.
#    (OPTIONAL) / (DEFAULT: "standalone")
#    Options: "standalone" (single node), "distributed" (HA, requires 4+ replicas)
# minio_mode: "standalone"

# -- Number of MinIO replicas.
#    (OPTIONAL) / (DEFAULT: 1)
#    NOTE: For distributed mode, minimum 4 replicas required
# minio_replicas: 1

# -- MinIO root username (admin account).
#    (OPTIONAL) / (DEFAULT: "admin")
# minio_root_user: "admin"

# -- MinIO root password (admin account).
#    (REQUIRED if minio_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 24 | tr -d '/+=' | head -c 24
# minio_root_password: ""

# -- Storage class for MinIO PVC.
#    (OPTIONAL) / (DEFAULT: "proxmox-csi")
# minio_storage_class: "proxmox-csi"

# -- Storage size for MinIO data.
#    (OPTIONAL) / (DEFAULT: "50Gi")
# minio_storage_size: "50Gi"

# ==============================================================================
# MINIO RESOURCE LIMITS
# ==============================================================================

# -- Memory request for MinIO.
#    (OPTIONAL) / (DEFAULT: "512Mi")
# minio_memory_request: "512Mi"

# -- Memory limit for MinIO.
#    (OPTIONAL) / (DEFAULT: "2Gi")
# minio_memory_limit: "2Gi"

# -- CPU request for MinIO.
#    (OPTIONAL) / (DEFAULT: "250m")
# minio_cpu_request: "250m"

# ==============================================================================
# MINIO CONSOLE INGRESS
# ==============================================================================

# -- Enable console HTTPRoute via kgateway.
#    (OPTIONAL) / (DEFAULT: false)
#    Creates minio.<domain> route for web console access
# minio_ingress_enabled: true

# -- Console hostname subdomain.
#    (OPTIONAL) / (DEFAULT: "minio")
#    Results in minio.<primary_domain>
# minio_console_hostname: "minio"

# ==============================================================================
# MINIO BUCKETS AND USERS
# ==============================================================================

# -- Buckets to create automatically.
#    (OPTIONAL) - List of bucket configurations
#    Policy options: "none", "public", "download", "upload"
# minio_buckets:
#   - name: obot-workspaces
#     policy: none
#   - name: backups
#     policy: none

# -- Service account users to create.
#    (OPTIONAL) - List of user configurations
#    Policy options: "readwrite", "readonly", "writeonly", "consoleAdmin"
#    NOTE: Access/secret keys should be generated securely
# minio_users:
#   - access_key: obot
#     secret_key: "generated-secret-key"
#     policy: readwrite

# ==============================================================================
# KAGENT CONFIGURATION (Optional - Kubernetes-native AI Agent Framework)
# ==============================================================================
# kagent is a CNCF sandbox project for building, deploying, and managing AI agents
# in Kubernetes. It provides declarative Agent/ModelConfig CRDs, pre-built agents
# (k8s, helm, cilium, observability), and MCP server orchestration via kmcp.
# REF: https://kagent.dev/docs/kagent/
# REF: docs/kagent-implementation-guide.md

# -- Enable kagent deployment.
#    (OPTIONAL) / (DEFAULT: false)
# kagent_enabled: true

# -- LLM provider for kagent agents.
#    (OPTIONAL) / (DEFAULT: "anthropic")
#    Options: "anthropic", "openai", "azure", "gemini", "ollama"
# kagent_provider: "anthropic"

# -- Default model name for agents.
#    (OPTIONAL) / (DEFAULT: "claude-3-5-haiku")
#    Examples: "claude-3-5-haiku", "gpt-4o", "gemini-pro"
# kagent_default_model: "claude-3-5-haiku"

# -- Anthropic API key (required if kagent_provider=anthropic).
#    (REQUIRED if using Anthropic) - Will be encrypted with SOPS
# kagent_anthropic_api_key: "sk-ant-xxx"

# -- OpenAI API key (required if kagent_provider=openai).
#    (REQUIRED if using OpenAI) - Will be encrypted with SOPS
# kagent_openai_api_key: "sk-xxx"

# -- OpenAI-compatible API base URL (for routing through LiteLLM).
#    (OPTIONAL) - Use this to route kagent requests through the AI Gateway
#    Example: "https://llms.<your-domain>/v1"
# kagent_openai_api_base: ""

# -- Google Gemini API key (required if kagent_provider=gemini).
#    (REQUIRED if using Gemini) - Will be encrypted with SOPS
# kagent_gemini_api_key: ""

# -- Azure OpenAI endpoint (required if kagent_provider=azure).
#    (REQUIRED if using Azure) - Your Azure OpenAI resource endpoint
#    Example: "https://your-resource.openai.azure.com"
# kagent_azure_endpoint: ""

# -- Azure OpenAI deployment name (required if kagent_provider=azure).
#    (REQUIRED if using Azure) - The deployment name for your model
# kagent_azure_deployment: ""

# -- Ollama host URL (required if kagent_provider=ollama).
#    (OPTIONAL) / (DEFAULT: "ollama.ollama.svc.cluster.local:11434")
#    Example: "http://localhost:11434" for local Ollama
# kagent_ollama_host: "ollama.ollama.svc.cluster.local:11434"

# ==============================================================================
# KAGENT UI CONFIGURATION
# ==============================================================================

# -- Enable kagent web UI.
#    (OPTIONAL) / (DEFAULT: false)
#    The UI provides chat interface and agent management at kagent.<domain>
# kagent_ui_enabled: false

# -- Number of UI replicas.
#    (OPTIONAL) / (DEFAULT: 1)
# kagent_ui_replicas: 1

# ==============================================================================
# KAGENT CONTROLLER CONFIGURATION
# ==============================================================================

# -- Number of controller replicas.
#    (OPTIONAL) / (DEFAULT: 1)
# kagent_controller_replicas: 1

# -- Controller log level.
#    (OPTIONAL) / (DEFAULT: "info")
#    Options: "debug", "info", "warn", "error"
# kagent_controller_log_level: "info"

# ==============================================================================
# KAGENT PRE-BUILT AGENTS
# ==============================================================================

# -- List of pre-built agents to enable.
#    (OPTIONAL) / (DEFAULT: ["k8s", "helm", "observability"])
#    Available agents: k8s, helm, cilium-debug, cilium-policy, cilium-manager,
#                      istio, kgateway, observability, promql, argo-rollouts
# kagent_agents_enabled:
#   - k8s
#   - helm
#   - observability

# -- Enable write operations for k8s-agent.
#    (OPTIONAL) / (DEFAULT: false)
#    WARNING: When true, k8s-agent can delete pods, patch deployments, etc.
#    Only enable this if you trust the agent's judgment for remediation actions.
# kagent_write_operations_enabled: false

# ==============================================================================
# KAGENT OBSERVABILITY (OpenTelemetry Tracing)
# ==============================================================================

# -- Enable OpenTelemetry tracing for agent operations.
#    (OPTIONAL) / (DEFAULT: false)
#    NOTE: Requires a tracing backend (Jaeger, Tempo, or OpenTelemetry Collector)
# kagent_otlp_enabled: false

# -- OTLP endpoint for trace collection.
#    (OPTIONAL) - Only used if kagent_otlp_enabled=true
#    Example with Jaeger: "http://jaeger-collector.jaeger.svc.cluster.local:4317"
#    Example with Tempo: "http://tempo.observability.svc.cluster.local:4317"
#    NOTE: kube-prometheus-stack does NOT natively expose OTLP - use Jaeger or Tempo
# kagent_otlp_endpoint: "http://jaeger-collector.jaeger.svc.cluster.local:4317"

# ==============================================================================
# KAGENT DATABASE CONFIGURATION
# ==============================================================================

# -- Database type for kagent.
#    (OPTIONAL) / (DEFAULT: "sqlite")
#    Options: "sqlite", "postgres"
#    NOTE: When "postgres" is selected, a CloudNativePG cluster is deployed
#    automatically. No external database is required.
# kagent_database_type: "sqlite"

# -- PostgreSQL database user (if kagent_database_type=postgres).
#    (OPTIONAL) / (DEFAULT: "kagent")
#    The CNPG bootstrap process uses this for the database owner.
# kagent_postgres_user: "kagent"

# -- PostgreSQL database password (if kagent_database_type=postgres).
#    (REQUIRED if postgres) - Will be encrypted with SOPS
#    Password for the kagent PostgreSQL user.
# kagent_postgres_password: ""

# -- CNPG PostgreSQL cluster replicas (if kagent_database_type=postgres).
#    (OPTIONAL) / (DEFAULT: 3)
#    Number of PostgreSQL instances in the CNPG cluster for HA.
# kagent_postgresql_replicas: 3

# -- CNPG PostgreSQL storage size (if kagent_database_type=postgres).
#    (OPTIONAL) / (DEFAULT: "10Gi")
#    Storage size for each PostgreSQL instance.
# kagent_postgresql_storage_size: "10Gi"

# ==============================================================================
# KAGENT MCP SERVER CONTROLLER (kmcp)
# ==============================================================================

# -- Enable kmcp controller for MCPServer CRD management.
#    (OPTIONAL) / (DEFAULT: false)
#    kmcp deploys and manages MCP servers declaratively via MCPServer CRD
kagent_kmcp_enabled: true
# ==============================================================================
# KAGENT GRAFANA MCP INTEGRATION
# ==============================================================================

# -- Grafana URL for grafana-mcp tool.
#    (OPTIONAL) / (DEFAULT: http://vm-grafana.observability.svc:80/api)
#    Points to the VictoriaMetrics Grafana - NOT a separate Grafana installation.
#    grafana-mcp is an MCP tool that lets kagent agents interact with Grafana.
# kagent_grafana_url: "http://vm-grafana.observability.svc:80/api"

# -- Grafana API key for grafana-mcp tool authentication.
#    (OPTIONAL) - Will be encrypted with SOPS via Flux valuesFrom
#    Create a Service Account with Editor role in Grafana UI:
#    Administration > Service Accounts > Add Service Account > Add Token
#    Note: If not set, grafana-mcp will use anonymous access (if enabled in Grafana)
#    The API key is stored in kagent-grafana-secret (SOPS-encrypted) and injected
#    via Flux valuesFrom - it never appears in the rendered HelmRelease.
# kagent_grafana_api_key: ""

# ==============================================================================
# LITELLM CONFIGURATION (Optional - LLM Proxy with Multi-Provider Routing)
# ==============================================================================
# LiteLLM is a unified AI Gateway for routing requests across Azure OpenAI,
# Anthropic, and other LLM providers with spend tracking, caching, and team management.
# REF: https://docs.litellm.ai/docs/
# REF: docs/LITELLM_DESIGN.md

# -- Enable LiteLLM deployment.
#    (OPTIONAL) / (DEFAULT: false)
# litellm_enabled: true

# -- LiteLLM master key (admin API access).
#    (REQUIRED if litellm_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -hex 32
#    NOTE: Must start with "sk-" prefix
# litellm_master_key: "sk-your-master-key"

# -- Salt key for encrypting API keys stored in database.
#    (REQUIRED if litellm_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -hex 16
#    WARNING: DO NOT change after adding models - will break existing encrypted keys
# litellm_salt_key: ""

# -- PostgreSQL password for LiteLLM database.
#    (REQUIRED if litellm_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 24
# litellm_db_password: ""

# -- Dragonfly (Redis-compatible) password for caching.
#    (REQUIRED if litellm_enabled) - Will be encrypted with SOPS
#    Generate with: openssl rand -base64 24
# litellm_cache_password: ""

# -- PostgreSQL connection URL (optional - auto-generated if not set).
#    (OPTIONAL) - Override the default DATABASE_URL for LiteLLM
#    Default: postgresql://litellm:<password>@litellm-db-rw.ai-system.svc.cluster.local:5432/litellm?sslmode=disable
# litellm_database_url: ""

# -- Redis/Dragonfly connection URL (optional - auto-generated if not set).
#    (OPTIONAL) - Override the default REDIS_URL for LiteLLM
#    Default: redis://:<password>@litellm-dragonfly.ai-system.svc.cluster.local:6379/0
# litellm_redis_url: ""

# -- Enable MCP server support (Open Source feature).
#    (OPTIONAL) / (DEFAULT: false)
#    Allows LiteLLM to act as an MCP server bridge for tool calling.
# litellm_mcp_enabled: false

# ==============================================================================
# LITELLM SCALING CONFIGURATION
# ==============================================================================

# -- Minimum replicas for HPA.
#    (OPTIONAL) / (DEFAULT: 2)
# litellm_replicas_min: 2

# -- Maximum replicas for HPA.
#    (OPTIONAL) / (DEFAULT: 5)
# litellm_replicas_max: 5

# -- CPU request for LiteLLM pods.
#    (OPTIONAL) / (DEFAULT: "500m")
# litellm_cpu_request: "500m"

# -- CPU limit for LiteLLM pods.
#    (OPTIONAL) / (DEFAULT: "2000m")
# litellm_cpu_limit: "2000m"

# -- Memory request for LiteLLM pods.
#    (OPTIONAL) / (DEFAULT: "512Mi")
# litellm_memory_request: "512Mi"

# -- Memory limit for LiteLLM pods.
#    (OPTIONAL) / (DEFAULT: "2Gi")
# litellm_memory_limit: "2Gi"

# ==============================================================================
# LITELLM POSTGRESQL CONFIGURATION
# ==============================================================================

# -- CNPG PostgreSQL cluster replicas.
#    (OPTIONAL) / (DEFAULT: 3)
#    PostgreSQL is used for spend tracking, user/team management, and model storage.
# litellm_postgresql_replicas: 3

# -- CNPG PostgreSQL storage size.
#    (OPTIONAL) / (DEFAULT: "20Gi")
# litellm_postgresql_storage_size: "20Gi"

# ==============================================================================
# LITELLM CACHE CONFIGURATION (Dragonfly)
# ==============================================================================

# -- Dragonfly memory limit.
#    (OPTIONAL) / (DEFAULT: "1Gi")
#    Dragonfly is used for caching responses, rate limiting, and router state.
# litellm_cache_memory: "1Gi"

# ==============================================================================
# LITELLM LANGFUSE OBSERVABILITY (Optional)
# ==============================================================================
# Langfuse provides team-based spend tracking and observability.
# REF: https://docs.litellm.ai/docs/observability/langfuse_integration

# -- Enable Langfuse observability integration.
#    (OPTIONAL) / (DEFAULT: false)
# litellm_langfuse_enabled: true

# -- Langfuse host URL.
#    (OPTIONAL) / (DEFAULT: "https://cloud.langfuse.com")
# litellm_langfuse_host: "https://cloud.langfuse.com"

# -- Langfuse public key.
#    (REQUIRED if litellm_langfuse_enabled) - From Langfuse dashboard
# litellm_langfuse_public_key: ""

# -- Langfuse secret key.
#    (REQUIRED if litellm_langfuse_enabled) - Will be encrypted with SOPS
# litellm_langfuse_secret_key: ""

# ==============================================================================
# COGNEE GRAPH RAG (Optional - requires obot_enabled)
# ==============================================================================
# Cognee provides Graph RAG capabilities using Neo4j for graph storage and
# pgvector for vector embeddings. Integrates with obot as an MCP server.
# REF: https://docs.cognee.ai/

# -- Enable Cognee Graph RAG integration.
#    (OPTIONAL) / (DEFAULT: false)
#    Requires: obot_enabled: true
# cognee_enabled: false

# -- Use dedicated CNPG cluster instead of extending obot-db.
#    (OPTIONAL) / (DEFAULT: true)
#    Recommended: true for resource isolation; false to share obot-db cluster
# cognee_dedicated_db: true

# -- PostgreSQL database name for Cognee.
#    (OPTIONAL) / (DEFAULT: "cognee")
# cognee_db_name: "cognee"

# -- PostgreSQL password for Cognee database.
#    (REQUIRED if cognee_enabled) - Generate with: openssl rand -base64 24
# cognee_db_password: ""

# -- Neo4j Community Edition password.
#    (REQUIRED if cognee_enabled) - Generate with: openssl rand -base64 24
# cognee_neo4j_password: ""

# -- Neo4j Community Edition version.
#    (OPTIONAL) / (DEFAULT: "5.26.0")
# cognee_neo4j_version: "5.26.0"

# -- Neo4j PVC storage size.
#    (OPTIONAL) / (DEFAULT: "10Gi")
# cognee_neo4j_storage_size: "10Gi"

# -- Embedding model for vector storage.
#    (OPTIONAL) / (DEFAULT: "text-embedding-3-large")
#    Options: text-embedding-3-large (3072 dim), text-embedding-3-small (1536 dim)
# cognee_embedding_model: "text-embedding-3-large"

# -- Embedding dimensions (must match model).
#    (OPTIONAL) / (DEFAULT: 3072 for text-embedding-3-large)
# cognee_embedding_dimensions: 3072

# -- LLM endpoint for Cognee processing.
#    (OPTIONAL) / (DEFAULT: "https://llms.${SECRET_DOMAIN}/v1")
#    Use ai-gw.${SECRET_DOMAIN} if using agentgateway instead of LiteLLM
# cognee_llm_base_url: "https://llms.${SECRET_DOMAIN}/v1"

# -- LiteLLM API key for Cognee LLM and embedding access.
#    (REQUIRED if cognee_enabled) - Use LiteLLM master key or dedicated key
#    This key is used for both LLM and embedding model access via LiteLLM proxy
# cognee_litellm_api_key: ""

# -- LLM model for Cognee processing.
#    (OPTIONAL) / (DEFAULT: "gpt-5-mini")
#    Model name or alias from LiteLLM config
# cognee_llm_model: "gpt-5-mini"

# -- MCP server name for Cognee (used in NetworkPolicy selectors).
#    (OPTIONAL) / (DEFAULT: "cognee-mcp")
#    Must match the MCP server registration name in Obot
# cognee_mcp_server_name: "cognee-mcp"

# ============================================================================
# COGNEE MCP SERVER CONFIGURATION (optional - enables MCP service deployment)
# ============================================================================
# Deploy Cognee MCP server for Model Context Protocol integration.
# Required for Cognee frontend UI MCP features and Obot MCP integration.

# -- Enable Cognee MCP server deployment.
#    (OPTIONAL) / (DEFAULT: false)
#    Deploys cognee-mcp service accessible by frontend and Obot
# cognee_mcp_enabled: false

# -- Cognee MCP Docker image version.
#    (OPTIONAL) / (DEFAULT: "main")
#    Uses ghcr.io/jrmatherly/cognee-mcp:<version>
# cognee_mcp_version: "main"

# -- Number of Cognee MCP replicas.
#    (OPTIONAL) / (DEFAULT: 1)
# cognee_mcp_replicas: 1

# -- CPU request for Cognee MCP pods.
#    (OPTIONAL) / (DEFAULT: "100m")
# cognee_mcp_resources_requests_cpu: "100m"

# -- Memory request for Cognee MCP pods.
#    (OPTIONAL) / (DEFAULT: "512Mi")
# cognee_mcp_resources_requests_memory: "512Mi"

# -- CPU limit for Cognee MCP pods.
#    (OPTIONAL) / (DEFAULT: "1000m")
# cognee_mcp_resources_limits_cpu: "1000m"

# -- Memory limit for Cognee MCP pods.
#    (OPTIONAL) / (DEFAULT: "2Gi")
# cognee_mcp_resources_limits_memory: "2Gi"

# ============================================================================
# COGNEE API SERVER CONFIGURATION (optional - requires cognee_enabled)
# ============================================================================
# Deploy Cognee as a standalone API server with web UI, independent of Obot MCP integration.
# Provides REST API at /api/* and UI at / for document ingestion, graph exploration, and search.

# -- Enable Cognee API server deployment.
#    (OPTIONAL) / (DEFAULT: false)
#    Deploys Cognee as a web service accessible at cognee.${SECRET_DOMAIN}
# cognee_api_enabled: false

# -- Cognee API hostname (subdomain).
#    (OPTIONAL) / (DEFAULT: "cognee-api")
#    Results in cognee-api.<primary_domain>
# cognee_api_hostname: "cognee-api"

# -- Gateway for Cognee routing.
#    (OPTIONAL) / (DEFAULT: "external")
#    Options: external, internal
# cognee_gateway: "external"

# -- Cognee Backend Docker image version.
#    (OPTIONAL) / (DEFAULT: "main")
#    Uses ghcr.io/jrmatherly/cognee:<version>
# cognee_version: "main"

# -- Number of Cognee API replicas.
#    (OPTIONAL) / (DEFAULT: 1)
# cognee_replicas: 1

# -- CPU request for Cognee API pods.
#    (OPTIONAL) / (DEFAULT: "100m")
# cognee_api_resources_requests_cpu: "100m"

# -- Memory request for Cognee API pods.
#    (OPTIONAL) / (DEFAULT: "512Mi")
# cognee_api_resources_requests_memory: "512Mi"

# -- CPU limit for Cognee API pods.
#    (OPTIONAL) / (DEFAULT: "2000m")
# cognee_api_resources_limits_cpu: "2000m"

# -- Memory limit for Cognee API pods.
#    (OPTIONAL) / (DEFAULT: "4Gi")
# cognee_api_resources_limits_memory: "4Gi"

# ============================================================================
# COGNEE FRONTEND CONFIGURATION (optional - requires cognee_api_enabled)
# ============================================================================
# Deploy Cognee Next.js frontend UI for document ingestion, graph exploration,
# and knowledge graph visualization.

# -- Enable Cognee Frontend deployment.
#    (OPTIONAL) / (DEFAULT: false)
#    Deploys frontend at cognee.${SECRET_DOMAIN}
# cognee_frontend_enabled: false

# -- Cognee Frontend hostname (subdomain).
#    (OPTIONAL) / (DEFAULT: "cognee")
#    Results in cognee.<primary_domain>
# cognee_frontend_hostname: "cognee"

# -- Cognee Frontend Docker image version.
#    (OPTIONAL) / (DEFAULT: "main")
#    Uses ghcr.io/jrmatherly/cognee-frontend:<version>
# cognee_frontend_version: "main"

# -- Number of Cognee Frontend replicas.
#    (OPTIONAL) / (DEFAULT: 1)
# cognee_frontend_replicas: 1

# -- Full URL for frontend (used for OAuth callbacks).
#    (OPTIONAL) / (DEFAULT: "https://cognee.${primary_domain}")
# cognee_frontend_url: "https://cognee.example.com"

# -- CPU request for Cognee Frontend pods.
#    (OPTIONAL) / (DEFAULT: "100m")
# cognee_frontend_resources_requests_cpu: "100m"

# -- Memory request for Cognee Frontend pods.
#    (OPTIONAL) / (DEFAULT: "256Mi")
# cognee_frontend_resources_requests_memory: "256Mi"

# -- CPU limit for Cognee Frontend pods.
#    (OPTIONAL) / (DEFAULT: "500m")
# cognee_frontend_resources_limits_cpu: "500m"

# -- Memory limit for Cognee Frontend pods.
#    (OPTIONAL) / (DEFAULT: "512Mi")
# cognee_frontend_resources_limits_memory: "512Mi"

# ============================================================================
# COGNEE AUTH0 CONFIGURATION (optional - for frontend authentication)
# ============================================================================
# Auth0 configuration for frontend authentication. Leave empty to disable.

# -- Auth0 domain.
#    (OPTIONAL) / (DEFAULT: "")
# cognee_auth0_domain: ""

# -- Auth0 client ID.
#    (OPTIONAL) / (DEFAULT: "")
# cognee_auth0_client_id: ""

# -- Auth0 client secret.
#    (OPTIONAL) / (DEFAULT: "") - Should be SOPS encrypted
# cognee_auth0_client_secret: ""

# -- Auth0 session secret.
#    (OPTIONAL) / (DEFAULT: "") - Should be SOPS encrypted
#    Generate with: openssl rand -base64 32
# cognee_auth0_secret: ""

# ============================================================================
# COGNEE JWT SECURITY (REQUIRED - v0.5.2+)
# ============================================================================
# JWT secrets are REQUIRED for the backend to start.
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(64))"

# -- JWT secret for FastAPI Users authentication.
#    (REQUIRED if cognee_api_enabled) - Must be at least 32 characters
#    SOPS encrypt: sops --encrypt --age <AGE_PUBLIC_KEY>
# cognee_jwt_secret: ""

# -- Reset password token secret.
#    (OPTIONAL) / (DEFAULT: uses cognee_jwt_secret)
#    For production, use a unique secret per token type
# cognee_reset_password_token_secret: ""

# -- Verification token secret.
#    (OPTIONAL) / (DEFAULT: uses cognee_jwt_secret)
#    For production, use a unique secret per token type
# cognee_verification_token_secret: ""

# ============================================================================
# COGNEE SECURITY SETTINGS (v0.5.2+)
# ============================================================================

# -- Enable authentication rate limiting.
#    (OPTIONAL) / (DEFAULT: true)
#    Protects against brute force login attacks
# cognee_auth_rate_limit_enabled: true

# -- Maximum login attempts per window.
#    (OPTIONAL) / (DEFAULT: 5)
# cognee_auth_rate_limit_login_requests: 5

# -- Login rate limit window in seconds.
#    (OPTIONAL) / (DEFAULT: 300)
# cognee_auth_rate_limit_login_window: 300

# -- Maximum OAuth route attempts per window.
#    (OPTIONAL) / (DEFAULT: 10)
# cognee_auth_rate_limit_oauth_requests: 10

# -- OAuth rate limit window in seconds.
#    (OPTIONAL) / (DEFAULT: 60)
# cognee_auth_rate_limit_oauth_window: 60

# -- Maximum callback route attempts per window.
#    (OPTIONAL) / (DEFAULT: 5)
# cognee_auth_rate_limit_callback_requests: 5

# -- Callback rate limit window in seconds.
#    (OPTIONAL) / (DEFAULT: 60)
# cognee_auth_rate_limit_callback_window: 60

# -- Enable SSRF protection.
#    (OPTIONAL) / (DEFAULT: true)
#    Prevents server-side request forgery attacks
# cognee_ssrf_protection_enabled: true

# -- Allow fetching private/internal IPs.
#    (OPTIONAL) / (DEFAULT: false)
#    Set to true only in trusted environments
# cognee_allow_private_urls: false

# -- Redis URL for OAuth state storage (multi-pod deployments).
#    (OPTIONAL) / (DEFAULT: "")
#    REQUIRED for multi-replica deployments - OAuth login will fail across pods without Redis
#    Example: redis://redis.ai-system.svc.cluster.local:6379/0
# cognee_oauth_state_redis_url: ""

# -- OAuth state time-to-live in seconds.
#    (OPTIONAL) / (DEFAULT: 600)
# cognee_oauth_state_ttl: 600

# ============================================================================
# COGNEE OIDC/KEYCLOAK AUTHENTICATION (OPTIONAL)
# ============================================================================
# Integrate with Keycloak or other OIDC providers for enterprise SSO.

# -- Enable OIDC authentication for backend.
#    (OPTIONAL) / (DEFAULT: false)
# cognee_oidc_enabled: false

# -- OIDC provider name (for display).
#    (OPTIONAL) / (DEFAULT: "keycloak")
# cognee_oidc_provider_name: "keycloak"

# -- OIDC client ID.
#    (REQUIRED if cognee_oidc_enabled) - SOPS encrypted
# cognee_oidc_client_id: ""

# -- OIDC client secret.
#    (REQUIRED if cognee_oidc_enabled) - SOPS encrypted
# cognee_oidc_client_secret: ""

# -- OIDC discovery/metadata URL.
#    (REQUIRED if cognee_oidc_enabled)
#    Example: https://keycloak.example.com/realms/cognee/.well-known/openid-configuration
# cognee_oidc_server_metadata_url: ""

# -- OIDC scopes to request.
#    (OPTIONAL) / (DEFAULT: "openid profile email")
# cognee_oidc_scopes: "openid profile email"

# -- OIDC claim for group membership.
#    (OPTIONAL) / (DEFAULT: "groups")
# cognee_oidc_group_claim: "groups"

# -- Default role for new OIDC users.
#    (OPTIONAL) / (DEFAULT: "viewer")
# cognee_oidc_default_role: "viewer"

# -- Auto-provision new users from OIDC.
#    (OPTIONAL) / (DEFAULT: true)
#    When true, creates user accounts automatically on first OIDC login
# cognee_oidc_auto_provision_users: true
